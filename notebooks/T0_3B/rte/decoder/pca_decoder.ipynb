{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from utils import load_hidden_representations_from_hdf5, read_templates_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "log_dir = \"/logfiles\"\n",
    "model = \"bigscience-T0_3B\" # bigscience-T0_B or bigscience-T0\n",
    "module = \"decoder\"\n",
    "task = \"rte\"\n",
    "# task = \"cb\"\n",
    "# task = \"wic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>template</th>\n",
       "      <th>category</th>\n",
       "      <th>includes_targets</th>\n",
       "      <th>targets</th>\n",
       "      <th>target_ids</th>\n",
       "      <th>shuffle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_3_yes_no_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} Yes or No?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt_3_true_false_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} True or False?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁True, ▁False</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt_3_cat_dog_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} Cat or Dog?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Cat, ▁Dog</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt_3_yes_no_without_targets</td>\n",
       "      <td>{premise} Question: {hypothesis}?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  \\\n",
       "0      gpt_3_yes_no_with_targets   \n",
       "1  gpt_3_true_false_with_targets   \n",
       "2     gpt_3_cat_dog_with_targets   \n",
       "3   gpt_3_yes_no_without_targets   \n",
       "\n",
       "                                          template     category  \\\n",
       "0      {premise} Question: {hypothesis} Yes or No?  instructive   \n",
       "1  {premise} Question: {hypothesis} True or False?  instructive   \n",
       "2     {premise} Question: {hypothesis} Cat or Dog?  instructive   \n",
       "3                {premise} Question: {hypothesis}?  instructive   \n",
       "\n",
       "   includes_targets        targets target_ids  shuffle  \n",
       "0              True      ▁Yes, ▁No       0, 1    False  \n",
       "1              True  ▁True, ▁False       0, 1    False  \n",
       "2              True     ▁Cat, ▁Dog       0, 1    False  \n",
       "3             False      ▁Yes, ▁No       0, 1    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/fixed_prompt.csv\")\n",
    "# df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/fixed_target_yes_no.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    # from: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == 'rte':\n",
    "    use_pattern = [\n",
    "        \"gpt_3_yes_no_with_targets\",\n",
    "        \"gpt_3_true_false_with_targets\",\n",
    "        \"gpt_3_cat_dog_with_targets\",\n",
    "        \"gpt_3_yes_no_without_targets\",\n",
    "    ]\n",
    "elif task == 'cb':\n",
    "    use_pattern = [\n",
    "        \"null_pattern\",\n",
    "        \"null_pattern_reversed\",\n",
    "        \"gpt_3_true_false_neither\",\n",
    "        \"gpt_3_yes_no_maybe\",\n",
    "        \"mnli_crowdsource\",\n",
    "        \"always_sometimes_never\",\n",
    "        \"based_on_previous_passage\",\n",
    "        \"infer\",\n",
    "        \"claim\",\n",
    "        \"consider\",\n",
    "        \"follow\",\n",
    "        \"imply\",\n",
    "        \"guaranteed\",\n",
    "        \"guaranteed_possible\",\n",
    "        \"justified\",\n",
    "        \"must_be_true\",\n",
    "        \"should_assume\",\n",
    "        \"take_the_following\",\n",
    "    ]\n",
    "elif task == 'wic':\n",
    "    use_pattern = [\n",
    "        \"gpt_3\",\n",
    "        \"gpt_3_yes_no\",\n",
    "        \"affirmation\",\n",
    "        \"grammar_homework\",\n",
    "        \"polysemous\",\n",
    "        \"question_context\",\n",
    "        \"question_meaning\",\n",
    "        \"question_meaning_yes_no\",\n",
    "        \"same_sense\",\n",
    "        \"similar_sense\",\n",
    "        \"similar_sense_yes_no\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: 0\tlayer: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4909.41it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4222.26it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5737.76it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5864.15it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:555: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ / total_var.sum()\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:555: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ / total_var.sum()\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:555: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ / total_var.sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:0; n_components: 1; variance explained: [nan]\n",
      "nan\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:0; n_components: 2; variance explained: [nan nan]\n",
      "nan\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:0; n_components: 3; variance explained: [nan nan nan]\n",
      "nan\n",
      "\n",
      "\n",
      "token: 0\tlayer: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4265.92it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5600.90it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5468.89it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5681.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:1; n_components: 1; variance explained: [0.9793358]\n",
      "0.9793358\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:1; n_components: 2; variance explained: [0.9793358  0.00613705]\n",
      "0.98547286\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:1; n_components: 3; variance explained: [0.9793358  0.00613705 0.00237561]\n",
      "0.98784846\n",
      "\n",
      "\n",
      "token: 0\tlayer: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3448.92it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5550.86it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5677.78it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5675.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:2; n_components: 1; variance explained: [0.99270725]\n",
      "0.99270725\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:2; n_components: 2; variance explained: [0.99270725 0.00193185]\n",
      "0.9946391\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:2; n_components: 3; variance explained: [0.99270725 0.00193186 0.00111519]\n",
      "0.9957543\n",
      "\n",
      "\n",
      "token: 0\tlayer: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3396.45it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5629.47it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5877.35it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5689.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:3; n_components: 1; variance explained: [0.99729466]\n",
      "0.99729466\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:3; n_components: 2; variance explained: [9.9729455e-01 5.6458561e-04]\n",
      "0.9978591\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:3; n_components: 3; variance explained: [9.9729455e-01 5.6458538e-04 4.9405295e-04]\n",
      "0.9983532\n",
      "\n",
      "\n",
      "token: 0\tlayer: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 2460.14it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5766.78it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5052.17it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5779.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:4; n_components: 1; variance explained: [0.9974827]\n",
      "0.9974827\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:4; n_components: 2; variance explained: [9.974827e-01 8.015798e-04]\n",
      "0.9982843\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:4; n_components: 3; variance explained: [9.9748290e-01 8.0158020e-04 4.0019894e-04]\n",
      "0.99868464\n",
      "\n",
      "\n",
      "token: 0\tlayer: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4694.55it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5456.97it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5635.45it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5661.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:5; n_components: 1; variance explained: [0.99667495]\n",
      "0.99667495\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:5; n_components: 2; variance explained: [0.9966751  0.00147543]\n",
      "0.9981505\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:5; n_components: 3; variance explained: [9.9667495e-01 1.4754346e-03 3.9233809e-04]\n",
      "0.9985427\n",
      "\n",
      "\n",
      "token: 0\tlayer: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4203.32it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5550.04it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5724.93it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4910.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:6; n_components: 1; variance explained: [0.9967464]\n",
      "0.9967464\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:6; n_components: 2; variance explained: [0.9967464  0.00139639]\n",
      "0.99814284\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:6; n_components: 3; variance explained: [9.9674642e-01 1.3963885e-03 3.7716641e-04]\n",
      "0.99852\n",
      "\n",
      "\n",
      "token: 0\tlayer: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4445.63it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5270.06it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5694.96it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5816.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:7; n_components: 1; variance explained: [0.99927235]\n",
      "0.99927235\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:7; n_components: 2; variance explained: [9.9927235e-01 6.2097504e-04]\n",
      "0.9998933\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:7; n_components: 3; variance explained: [9.9927235e-01 6.2097487e-04 2.5095336e-05]\n",
      "0.9999184\n",
      "\n",
      "\n",
      "token: 0\tlayer: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4657.61it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5375.55it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5619.02it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5710.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:8; n_components: 1; variance explained: [0.9992556]\n",
      "0.9992556\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:8; n_components: 2; variance explained: [9.9925566e-01 6.2647316e-04]\n",
      "0.9998821\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:8; n_components: 3; variance explained: [9.9925566e-01 6.2647351e-04 2.4874504e-05]\n",
      "0.99990696\n",
      "\n",
      "\n",
      "token: 0\tlayer: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3834.09it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5602.73it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5875.24it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5848.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:9; n_components: 1; variance explained: [0.9992064]\n",
      "0.9992064\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:9; n_components: 2; variance explained: [9.9920654e-01 6.6280115e-04]\n",
      "0.99986935\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:9; n_components: 3; variance explained: [9.9920642e-01 6.6280103e-04 2.3487144e-05]\n",
      "0.9998927\n",
      "\n",
      "\n",
      "token: 0\tlayer: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3168.15it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5466.37it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5556.27it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5695.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:10; n_components: 1; variance explained: [0.9990725]\n",
      "0.9990725\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:10; n_components: 2; variance explained: [9.9907249e-01 7.6821516e-04]\n",
      "0.99984074\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:10; n_components: 3; variance explained: [9.9907249e-01 7.6821516e-04 2.7088341e-05]\n",
      "0.9998678\n",
      "\n",
      "\n",
      "token: 0\tlayer: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4590.48it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5387.36it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5806.85it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5898.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:11; n_components: 1; variance explained: [0.99861383]\n",
      "0.99861383\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:11; n_components: 2; variance explained: [0.99861383 0.00120914]\n",
      "0.999823\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:11; n_components: 3; variance explained: [9.9861389e-01 1.2091356e-03 3.4425571e-05]\n",
      "0.9998575\n",
      "\n",
      "\n",
      "token: 0\tlayer: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4727.99it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5085.79it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5727.13it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5881.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:12; n_components: 1; variance explained: [0.9983611]\n",
      "0.9983611\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:12; n_components: 2; variance explained: [0.9983613  0.00145354]\n",
      "0.9998148\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:12; n_components: 3; variance explained: [9.9836111e-01 1.4535425e-03 3.2697615e-05]\n",
      "0.99984735\n",
      "\n",
      "\n",
      "token: 0\tlayer: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4262.83it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5369.09it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5601.98it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5746.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:13; n_components: 1; variance explained: [0.99753654]\n",
      "0.99753654\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:13; n_components: 2; variance explained: [0.99753654 0.00183825]\n",
      "0.9993748\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:13; n_components: 3; variance explained: [9.9753648e-01 1.8382476e-03 1.4676536e-04]\n",
      "0.9995215\n",
      "\n",
      "\n",
      "token: 0\tlayer: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4625.68it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5473.76it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5470.20it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5707.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:14; n_components: 1; variance explained: [0.9971152]\n",
      "0.9971152\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:14; n_components: 2; variance explained: [0.9971152  0.00215407]\n",
      "0.99926925\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:14; n_components: 3; variance explained: [9.9711519e-01 2.1540679e-03 1.6254191e-04]\n",
      "0.9994318\n",
      "\n",
      "\n",
      "token: 0\tlayer: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4713.22it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5438.20it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5490.34it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5972.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:15; n_components: 1; variance explained: [0.99591947]\n",
      "0.99591947\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:15; n_components: 2; variance explained: [0.99591947 0.0021096 ]\n",
      "0.99802905\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:15; n_components: 3; variance explained: [0.99591947 0.0021096  0.00105026]\n",
      "0.99907935\n",
      "\n",
      "\n",
      "token: 0\tlayer: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4466.59it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5410.27it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5684.53it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5449.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:16; n_components: 1; variance explained: [0.9928606]\n",
      "0.9928606\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:16; n_components: 2; variance explained: [0.99286073 0.0026184 ]\n",
      "0.9954791\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:16; n_components: 3; variance explained: [0.99286073 0.0026184  0.00133107]\n",
      "0.9968102\n",
      "\n",
      "\n",
      "token: 0\tlayer: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4436.43it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5531.28it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5036.40it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4514.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:17; n_components: 1; variance explained: [0.99199384]\n",
      "0.99199384\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:17; n_components: 2; variance explained: [0.99199384 0.0026178 ]\n",
      "0.9946116\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:17; n_components: 3; variance explained: [0.9919937  0.0026178  0.00148036]\n",
      "0.99609184\n",
      "\n",
      "\n",
      "token: 0\tlayer: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4251.13it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4927.61it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5424.06it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5895.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:18; n_components: 1; variance explained: [0.9800054]\n",
      "0.9800054\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:18; n_components: 2; variance explained: [0.9800054  0.00545339]\n",
      "0.9854588\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:18; n_components: 3; variance explained: [0.9800054  0.00545339 0.00313694]\n",
      "0.9885957\n",
      "\n",
      "\n",
      "token: 0\tlayer: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4645.43it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5178.50it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5558.00it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5909.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:19; n_components: 1; variance explained: [0.94800496]\n",
      "0.94800496\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:19; n_components: 2; variance explained: [0.9480051  0.01246161]\n",
      "0.9604667\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:19; n_components: 3; variance explained: [0.94800496 0.01246161 0.00926181]\n",
      "0.96972835\n",
      "\n",
      "\n",
      "token: 0\tlayer: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4712.07it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4917.33it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5650.17it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5705.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:20; n_components: 1; variance explained: [0.86167365]\n",
      "0.86167365\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:20; n_components: 2; variance explained: [0.86167365 0.03745803]\n",
      "0.89913166\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:20; n_components: 3; variance explained: [0.86167365 0.03745805 0.02467528]\n",
      "0.923807\n",
      "\n",
      "\n",
      "token: 0\tlayer: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4685.86it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5553.72it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5886.94it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4675.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:21; n_components: 1; variance explained: [0.7608182]\n",
      "0.7608182\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:21; n_components: 2; variance explained: [0.7608182  0.04810777]\n",
      "0.8089259\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:21; n_components: 3; variance explained: [0.7608183  0.04810778 0.03248793]\n",
      "0.84141403\n",
      "\n",
      "\n",
      "token: 0\tlayer: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4579.35it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5271.47it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5898.95it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5926.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:22; n_components: 1; variance explained: [0.9019495]\n",
      "0.9019495\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:22; n_components: 2; variance explained: [0.9019495  0.01591462]\n",
      "0.91786414\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:22; n_components: 3; variance explained: [0.9019495  0.01591463 0.01015158]\n",
      "0.9280157\n",
      "\n",
      "\n",
      "token: 0\tlayer: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4504.99it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5420.06it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5656.00it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5545.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:23; n_components: 1; variance explained: [0.68323934]\n",
      "0.68323934\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:23; n_components: 2; variance explained: [0.6832395  0.05124732]\n",
      "0.7344868\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:23; n_components: 3; variance explained: [0.6832395  0.05124734 0.02409185]\n",
      "0.7585787\n",
      "\n",
      "\n",
      "token: 0\tlayer: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3648.16it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5706.48it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5745.79it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4812.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:24; n_components: 1; variance explained: [0.7363083]\n",
      "0.7363083\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:24; n_components: 2; variance explained: [0.7363082  0.08087158]\n",
      "0.8171798\n",
      "model:bigscience-T0_3B; module:decoder; token:0; layer:24; n_components: 3; variance explained: [0.7363083  0.08087157 0.03402222]\n",
      "0.8512021\n",
      "\n",
      "\n",
      "token: 1\tlayer: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3780.68it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5714.23it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5951.78it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5879.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:0; n_components: 1; variance explained: [0.33654103]\n",
      "0.33654103\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:0; n_components: 2; variance explained: [0.33654103 0.17927758]\n",
      "0.5158186\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:0; n_components: 3; variance explained: [0.33654115 0.17927758 0.11174927]\n",
      "0.627568\n",
      "\n",
      "\n",
      "token: 1\tlayer: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3137.99it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5414.53it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4124.34it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5840.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:1; n_components: 1; variance explained: [0.36220828]\n",
      "0.36220828\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:1; n_components: 2; variance explained: [0.3622085  0.17854315]\n",
      "0.54075164\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:1; n_components: 3; variance explained: [0.3622087  0.17854315 0.10485899]\n",
      "0.6456108\n",
      "\n",
      "\n",
      "token: 1\tlayer: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4637.18it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5302.12it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5621.79it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5581.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:2; n_components: 1; variance explained: [0.3821908]\n",
      "0.3821908\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:2; n_components: 2; variance explained: [0.3821908  0.18429364]\n",
      "0.56648445\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:2; n_components: 3; variance explained: [0.3821909  0.18429354 0.09259874]\n",
      "0.6590832\n",
      "\n",
      "\n",
      "token: 1\tlayer: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4680.39it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5656.86it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5591.27it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5729.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:3; n_components: 1; variance explained: [0.5267851]\n",
      "0.5267851\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:3; n_components: 2; variance explained: [0.52678496 0.15082821]\n",
      "0.67761314\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:3; n_components: 3; variance explained: [0.5267851  0.15082811 0.0656416 ]\n",
      "0.7432548\n",
      "\n",
      "\n",
      "token: 1\tlayer: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4428.37it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5507.83it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5620.16it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5607.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:4; n_components: 1; variance explained: [0.62293273]\n",
      "0.62293273\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:4; n_components: 2; variance explained: [0.62293273 0.12134928]\n",
      "0.744282\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:4; n_components: 3; variance explained: [0.62293273 0.12134929 0.04973058]\n",
      "0.7940126\n",
      "\n",
      "\n",
      "token: 1\tlayer: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4430.95it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5452.70it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5540.90it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5593.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:5; n_components: 1; variance explained: [0.68717915]\n",
      "0.68717915\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:5; n_components: 2; variance explained: [0.68717897 0.10915637]\n",
      "0.79633534\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:5; n_components: 3; variance explained: [0.68717897 0.10915639 0.04104463]\n",
      "0.83738\n",
      "\n",
      "\n",
      "token: 1\tlayer: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4820.38it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4128.84it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5782.89it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5745.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:6; n_components: 1; variance explained: [0.75479645]\n",
      "0.75479645\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:6; n_components: 2; variance explained: [0.75479627 0.0830625 ]\n",
      "0.8378588\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:6; n_components: 3; variance explained: [0.75479627 0.08306252 0.03256497]\n",
      "0.8704238\n",
      "\n",
      "\n",
      "token: 1\tlayer: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4277.54it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5668.28it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5695.32it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5604.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:7; n_components: 1; variance explained: [0.9510407]\n",
      "0.9510407\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:7; n_components: 2; variance explained: [0.9510407 0.0169748]\n",
      "0.9680155\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:7; n_components: 3; variance explained: [0.9510407  0.01697479 0.00619441]\n",
      "0.9742099\n",
      "\n",
      "\n",
      "token: 1\tlayer: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3984.85it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4217.63it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5605.49it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5644.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:8; n_components: 1; variance explained: [0.95102715]\n",
      "0.95102715\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:8; n_components: 2; variance explained: [0.95102715 0.01690965]\n",
      "0.9679368\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:8; n_components: 3; variance explained: [0.951027   0.01690967 0.00616446]\n",
      "0.97410107\n",
      "\n",
      "\n",
      "token: 1\tlayer: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3933.62it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5306.31it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5674.51it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5651.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:9; n_components: 1; variance explained: [0.94811386]\n",
      "0.94811386\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:9; n_components: 2; variance explained: [0.94811386 0.016416  ]\n",
      "0.9645299\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:9; n_components: 3; variance explained: [0.94811386 0.01641601 0.0075998 ]\n",
      "0.97212964\n",
      "\n",
      "\n",
      "token: 1\tlayer: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4691.08it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5521.39it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5185.60it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5620.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:10; n_components: 1; variance explained: [0.9412988]\n",
      "0.9412988\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:10; n_components: 2; variance explained: [0.94129896 0.01937332]\n",
      "0.96067226\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:10; n_components: 3; variance explained: [0.9412988  0.01937334 0.00769094]\n",
      "0.9683631\n",
      "\n",
      "\n",
      "token: 1\tlayer: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3946.07it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5766.30it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5763.12it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5432.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:11; n_components: 1; variance explained: [0.91718054]\n",
      "0.91718054\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:11; n_components: 2; variance explained: [0.91718054 0.02620845]\n",
      "0.943389\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:11; n_components: 3; variance explained: [0.9171807  0.02620846 0.01135956]\n",
      "0.95474875\n",
      "\n",
      "\n",
      "token: 1\tlayer: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4702.17it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5099.85it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4993.67it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5550.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:12; n_components: 1; variance explained: [0.90168214]\n",
      "0.90168214\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:12; n_components: 2; variance explained: [0.90168214 0.03151163]\n",
      "0.9331938\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:12; n_components: 3; variance explained: [0.90168214 0.03151165 0.01457632]\n",
      "0.9477701\n",
      "\n",
      "\n",
      "token: 1\tlayer: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4525.06it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5576.46it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5627.73it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5914.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:13; n_components: 1; variance explained: [0.875403]\n",
      "0.875403\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:13; n_components: 2; variance explained: [0.875403   0.04021634]\n",
      "0.9156193\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:13; n_components: 3; variance explained: [0.875403   0.04021634 0.01938534]\n",
      "0.93500465\n",
      "\n",
      "\n",
      "token: 1\tlayer: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4233.06it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5721.99it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5618.04it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5891.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:14; n_components: 1; variance explained: [0.8336765]\n",
      "0.8336765\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:14; n_components: 2; variance explained: [0.83367664 0.05111016]\n",
      "0.8847868\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:14; n_components: 3; variance explained: [0.83367664 0.05111017 0.02857251]\n",
      "0.9133593\n",
      "\n",
      "\n",
      "token: 1\tlayer: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4489.61it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5322.11it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4466.47it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4901.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:15; n_components: 1; variance explained: [0.7560332]\n",
      "0.7560332\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:15; n_components: 2; variance explained: [0.75603336 0.07091186]\n",
      "0.82694525\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:15; n_components: 3; variance explained: [0.75603336 0.07091183 0.05212753]\n",
      "0.8790727\n",
      "\n",
      "\n",
      "token: 1\tlayer: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4236.79it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4891.88it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5348.79it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5584.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:16; n_components: 1; variance explained: [0.6411451]\n",
      "0.6411451\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:16; n_components: 2; variance explained: [0.6411452  0.09926774]\n",
      "0.74041295\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:16; n_components: 3; variance explained: [0.6411452  0.09926774 0.0905076 ]\n",
      "0.8309206\n",
      "\n",
      "\n",
      "token: 1\tlayer: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4551.08it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5361.58it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5534.67it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5074.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:17; n_components: 1; variance explained: [0.52200425]\n",
      "0.52200425\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:17; n_components: 2; variance explained: [0.5220041  0.13480185]\n",
      "0.656806\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:17; n_components: 3; variance explained: [0.52200407 0.13480185 0.11880279]\n",
      "0.7756087\n",
      "\n",
      "\n",
      "token: 1\tlayer: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3035.22it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5679.70it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4062.80it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5812.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:18; n_components: 1; variance explained: [0.35093805]\n",
      "0.35093805\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:18; n_components: 2; variance explained: [0.35093814 0.19303565]\n",
      "0.5439738\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:18; n_components: 3; variance explained: [0.35093823 0.19303574 0.15172097]\n",
      "0.6956949\n",
      "\n",
      "\n",
      "token: 1\tlayer: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4417.24it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5535.91it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5339.94it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5548.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:19; n_components: 1; variance explained: [0.22249432]\n",
      "0.22249432\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:19; n_components: 2; variance explained: [0.22249407 0.20711406]\n",
      "0.4296081\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:19; n_components: 3; variance explained: [0.22249402 0.20711406 0.15660514]\n",
      "0.58621323\n",
      "\n",
      "\n",
      "token: 1\tlayer: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4092.75it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4215.81it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 6067.46it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5983.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:20; n_components: 1; variance explained: [0.311665]\n",
      "0.311665\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:20; n_components: 2; variance explained: [0.3116652  0.20963104]\n",
      "0.52129626\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:20; n_components: 3; variance explained: [0.31166497 0.20963083 0.13055159]\n",
      "0.65184736\n",
      "\n",
      "\n",
      "token: 1\tlayer: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4431.49it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4605.75it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5863.49it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5805.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:21; n_components: 1; variance explained: [0.49190488]\n",
      "0.49190488\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:21; n_components: 2; variance explained: [0.49190465 0.15841812]\n",
      "0.6503228\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:21; n_components: 3; variance explained: [0.49190488 0.15841812 0.08789162]\n",
      "0.7382147\n",
      "\n",
      "\n",
      "token: 1\tlayer: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3409.02it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5383.69it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5887.09it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5903.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:22; n_components: 1; variance explained: [0.57567465]\n",
      "0.57567465\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:22; n_components: 2; variance explained: [0.5756748  0.14866985]\n",
      "0.7243446\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:22; n_components: 3; variance explained: [0.57567495 0.14866976 0.06921825]\n",
      "0.793563\n",
      "\n",
      "\n",
      "token: 1\tlayer: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4679.73it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5730.40it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4761.37it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4432.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:23; n_components: 1; variance explained: [0.6629282]\n",
      "0.6629282\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:23; n_components: 2; variance explained: [0.66292816 0.13095386]\n",
      "0.793882\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:23; n_components: 3; variance explained: [0.6629281  0.13095388 0.04393126]\n",
      "0.83781326\n",
      "\n",
      "\n",
      "token: 1\tlayer: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4663.85it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5132.52it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5468.92it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5878.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:24; n_components: 1; variance explained: [0.86665285]\n",
      "0.86665285\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:24; n_components: 2; variance explained: [0.86665285 0.0853231 ]\n",
      "0.95197594\n",
      "model:bigscience-T0_3B; module:decoder; token:1; layer:24; n_components: 3; variance explained: [0.86665285 0.08532301 0.01280805]\n",
      "0.96478385\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(2):\n",
    "    # for layer in range(0, 10):\n",
    "    for layer in range(0, 25):\n",
    "    # for layer in range(24, 25):\n",
    "        print(f\"token: {t}\\tlayer: {layer}\")\n",
    "        file_names, prompt_names = [], []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            if row['name'] in use_pattern:\n",
    "                file_names.append(f\"{task}/{model}/{module}/{row['name']}/hidden_represenations_t{t}_layer{layer}_avg.hdf5\",)\n",
    "                prompt_names.append(row['name'])\n",
    "\n",
    "\n",
    "        # load hidden representations from hdf5 file\n",
    "        representations = None\n",
    "        classes = []\n",
    "        n_sequences = 0\n",
    "\n",
    "        for idx, file_name in enumerate(file_names):\n",
    "            hidden_representations = load_hidden_representations_from_hdf5(os.path.join(log_dir, file_name))\n",
    "            # print(hidden_representations.shape)\n",
    "            n_sequences = hidden_representations.shape[0]\n",
    "\n",
    "            if representations is None:\n",
    "                representations = hidden_representations\n",
    "            else:\n",
    "                representations = np.concatenate((representations, hidden_representations), axis=0)\n",
    "\n",
    "            classes += n_sequences * [idx] # assign representations to classes\n",
    "        \n",
    "        classes = np.asarray(classes)\n",
    "\n",
    "        # shuffle representations and classes\n",
    "        X, y = unison_shuffled_copies(representations, classes)\n",
    "        print(X.shape, y.shape)\n",
    "\n",
    "        # perform PCA on hidden representations\n",
    "        print('PCA for prompts:', prompt_names)\n",
    "\n",
    "        for n_components in range(1, 4):\n",
    "            pca = PCA(n_components=n_components)\n",
    "            pca.fit(X)\n",
    "\n",
    "            # variance explained by each of the principal components\n",
    "            print(f\"model:{model}; module:{module}; token:{t}; layer:{layer}; n_components: {n_components}; variance explained: {pca.explained_variance_ratio_}\")\n",
    "            print(np.sum(pca.explained_variance_ratio_))\n",
    "        print('\\n')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
