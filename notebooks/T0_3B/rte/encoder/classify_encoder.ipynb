{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from utils import load_hidden_representations_from_hdf5, read_templates_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "log_dir = \"/logfiles\"\n",
    "model = \"bigscience-T0_3B\"\n",
    "module = \"encoder\"\n",
    "task = \"rte\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions\n",
    "assert model == \"bigscience-T0_3B\"\n",
    "assert module == \"encoder\"\n",
    "assert task == \"rte\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/all.csv\")\n",
    "# df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/fixed_prompt.csv\")\n",
    "# df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/fixed_target_yes_no.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    # from: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pattern = [\n",
    "    \"gpt_3_yes_no_with_targets\",\n",
    "    \"mnli_crowdsource_with_targets\",\n",
    "    \"based_on_previous_passage_with_targets\",\n",
    "    \"infer_with_targets\",\n",
    "    # \"follow_with_targets\",\n",
    "    # \"imply_with_targets\",\n",
    "    # \"guaranteed_with_targets\",\n",
    "    # \"justified_with_targets\",\n",
    "    # \"must_be_true_with_targets\",\n",
    "    # \"should_assume_with_targets\",\n",
    "    # \"gpt_3_true_false_with_targets\",\n",
    "    # \"gpt_3_cat_dog_with_targets\",\n",
    "    # \"gpt_3_cat_dog_with_targets_yes_no\",\n",
    "    # \"gpt_3_yes_no_without_targets\",\n",
    "    # \"words_appear_with_targets\",\n",
    "    # \"similar_words_with_targets\",\n",
    "    # \"start_with_the_with_targets\",\n",
    "    # \"same_meaning_with_targets\",\n",
    "    # \"paraphrase_with_targets\",\n",
    "    # \"paraphrase_r_with_targets\",\n",
    "    # \"summarize_with_targets\",\n",
    "    # \"inflection_with_targets\",\n",
    "    # \"null_pattern_with_targets\",\n",
    "    # \"null_pattern_r_with_targets\",\n",
    "    # \"null_pattern_without_targets\",\n",
    "    # \"null_pattern_r_without_targets\",\n",
    "    # \"premise_only_with_targets\",\n",
    "    # \"premise_only_without_targets\",\n",
    "    # \"hypothesis_only_with_targets\",\n",
    "    # \"hypothesis_only_without_targets\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in range(0, 3):\n",
    "for layer in range(0, 25):\n",
    "# for layer in range(24, 25):\n",
    "    \n",
    "    print(\"layer:\", layer)\n",
    "    file_names, prompt_names = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if row['name'] in use_pattern:\n",
    "            # file_names.append(f\"{task}/{model}/{module}/{row['name']}/hidden_represenations_layer{layer}_avg.hdf5\",)\n",
    "            file_names.append(f\"{task}/{model}/{module}/{row['name']}/hidden_represenations_layer{layer}_avg-nopad.hdf5\",)\n",
    "            prompt_names.append(row['name'])\n",
    "\n",
    "    # load hidden representations from hdf5 file\n",
    "    representations = None\n",
    "    classes = []\n",
    "    n_sequences = 0\n",
    "\n",
    "    for idx, file_name in enumerate(file_names):\n",
    "        hidden_representations = load_hidden_representations_from_hdf5(os.path.join(log_dir, file_name))\n",
    "        # take only first 100 samples\n",
    "        hidden_representations = hidden_representations[:100, :]\n",
    "        # print(hidden_representations.shape)\n",
    "        n_sequences = hidden_representations.shape[0]\n",
    "\n",
    "        if representations is None:\n",
    "            representations = hidden_representations\n",
    "        else:\n",
    "            representations = np.concatenate((representations, hidden_representations), axis=0)\n",
    "\n",
    "        # use pattern id as label\n",
    "        # classes += n_sequences * [idx] # assign representations to classes\n",
    "        # use sample id as label\n",
    "        classes += list(range(n_sequences)) # assign representations to classes\n",
    "        \n",
    "    classes = np.asarray(classes)\n",
    "    # print(classes)\n",
    "\n",
    "    X, y = representations, classes\n",
    "    # shuffle representations and classes\n",
    "    # X, y = unison_shuffled_coSpies(X, y)\n",
    "    print(X.shape, y.shape)\n",
    "    # print(y)\n",
    "\n",
    "    # train linear classifier\n",
    "    # multi_class='multinomial' uses a CE loss\n",
    "    # print('classifying between:', prompt_names)\n",
    "    print('classifying input ids for prompts:', prompt_names)\n",
    "    clf = LogisticRegression(random_state=0, max_iter=1000, multi_class='multinomial').fit(X, y)\n",
    "    \n",
    "    print(f'layer={layer}; accuracy on training data: ', clf.score(X, y))\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in range(0, 3):\n",
    "for layer in range(0, 25):\n",
    "# for layer in range(24, 25):\n",
    "    \n",
    "    print(\"layer:\", layer)\n",
    "    file_names, prompt_names = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if row['name'] in use_pattern:\n",
    "            # file_names.append(f\"{task}/{model}/{module}/{row['name']}/hidden_represenations_layer{layer}_avg.hdf5\",)\n",
    "            file_names.append(f\"{task}/{model}/{module}/{row['name']}/hidden_represenations_layer{layer}_avg-nopad.hdf5\",)\n",
    "            prompt_names.append(row['name'])\n",
    "\n",
    "    # load hidden representations from hdf5 file\n",
    "    representations = None\n",
    "    classes = []\n",
    "    n_sequences = 0\n",
    "\n",
    "    for idx, file_name in enumerate(file_names):\n",
    "        hidden_representations = load_hidden_representations_from_hdf5(os.path.join(log_dir, file_name))\n",
    "        # take only first 100 samples\n",
    "        hidden_representations = hidden_representations[:100, :]\n",
    "        # print(hidden_representations.shape)\n",
    "        n_sequences = hidden_representations.shape[0]\n",
    "\n",
    "        if representations is None:\n",
    "            representations = hidden_representations\n",
    "        else:\n",
    "            representations = np.concatenate((representations, hidden_representations), axis=0)\n",
    "\n",
    "        # use pattern id as label\n",
    "        classes += n_sequences * [idx] # assign representations to classes\n",
    "        # use sample id as label\n",
    "        # classes += list(range(n_sequences)) # assign representations to classes\n",
    "        \n",
    "    classes = np.asarray(classes)\n",
    "    # print(classes)\n",
    "\n",
    "    X, y = representations, classes\n",
    "    # shuffle representations and classes\n",
    "    # X, y = unison_shuffled_coSpies(X, y)\n",
    "    print(X.shape, y.shape)\n",
    "    # print(y)\n",
    "\n",
    "    # train linear classifier\n",
    "    # multi_class='multinomial' uses a CE loss\n",
    "    print('classifying between:', prompt_names)\n",
    "    # print('classifying input ids for prompts:', prompt_names)\n",
    "    clf = LogisticRegression(random_state=0, max_iter=1000, multi_class='multinomial').fit(X, y)\n",
    "    \n",
    "    print(f'layer={layer}; accuracy on training data: ', clf.score(X, y))\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
