{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from utils import load_hidden_representations_from_hdf5, read_templates_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "log_dir = \"/logfiles\"\n",
    "model = \"bigscience-T0_3B\" # bigscience-T0_B or bigscience-T0\n",
    "module = \"encoder\" # encoder\n",
    "task = \"rte\"\n",
    "# task = \"cb\"\n",
    "# task = \"wic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert module == \"encoder\" # TODO(mm): support decoder as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>template</th>\n",
       "      <th>category</th>\n",
       "      <th>includes_targets</th>\n",
       "      <th>targets</th>\n",
       "      <th>target_ids</th>\n",
       "      <th>shuffle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_3_yes_no_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} Yes or No?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt_3_true_false_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} True or False?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁True, ▁False</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt_3_cat_dog_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} Cat or Dog?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Cat, ▁Dog</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt_3_yes_no_without_targets</td>\n",
       "      <td>{premise} Question: {hypothesis}?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  \\\n",
       "0      gpt_3_yes_no_with_targets   \n",
       "1  gpt_3_true_false_with_targets   \n",
       "2     gpt_3_cat_dog_with_targets   \n",
       "3   gpt_3_yes_no_without_targets   \n",
       "\n",
       "                                          template     category  \\\n",
       "0      {premise} Question: {hypothesis} Yes or No?  instructive   \n",
       "1  {premise} Question: {hypothesis} True or False?  instructive   \n",
       "2     {premise} Question: {hypothesis} Cat or Dog?  instructive   \n",
       "3                {premise} Question: {hypothesis}?  instructive   \n",
       "\n",
       "   includes_targets        targets target_ids  shuffle  \n",
       "0              True      ▁Yes, ▁No       0, 1    False  \n",
       "1              True  ▁True, ▁False       0, 1    False  \n",
       "2              True     ▁Cat, ▁Dog       0, 1    False  \n",
       "3             False      ▁Yes, ▁No       0, 1    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/fixed_prompt.csv\")\n",
    "# df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/fixed_target_yes_no.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    # from: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == 'rte':\n",
    "    use_pattern = [\n",
    "        \"gpt_3_yes_no_with_targets\",\n",
    "        \"gpt_3_true_false_with_targets\",\n",
    "        \"gpt_3_cat_dog_with_targets\",\n",
    "        \"gpt_3_yes_no_without_targets\",\n",
    "    ]\n",
    "elif task == 'cb':\n",
    "    use_pattern = [\n",
    "        \"null_pattern\",\n",
    "        \"null_pattern_reversed\",\n",
    "        \"gpt_3_true_false_neither\",\n",
    "        \"gpt_3_yes_no_maybe\",\n",
    "        \"mnli_crowdsource\",\n",
    "        \"always_sometimes_never\",\n",
    "        \"based_on_previous_passage\",\n",
    "        \"infer\",\n",
    "        \"claim\",\n",
    "        \"consider\",\n",
    "        \"follow\",\n",
    "        \"imply\",\n",
    "        \"guaranteed\",\n",
    "        \"guaranteed_possible\",\n",
    "        \"justified\",\n",
    "        \"must_be_true\",\n",
    "        \"should_assume\",\n",
    "        \"take_the_following\",\n",
    "    ]\n",
    "elif task == 'wic':\n",
    "    use_pattern = [\n",
    "        \"gpt_3\",\n",
    "        \"gpt_3_yes_no\",\n",
    "        \"affirmation\",\n",
    "        \"grammar_homework\",\n",
    "        \"polysemous\",\n",
    "        \"question_context\",\n",
    "        \"question_meaning\",\n",
    "        \"question_meaning_yes_no\",\n",
    "        \"same_sense\",\n",
    "        \"similar_sense\",\n",
    "        \"similar_sense_yes_no\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5467.12it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5852.48it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5667.95it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4997.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:0; n_components: 1; variance explained: [0.91322815]\n",
      "0.91322815\n",
      "model:bigscience-T0_3B; module:encoder; layer:0; n_components: 2; variance explained: [0.91322803 0.00506137]\n",
      "0.9182894\n",
      "model:bigscience-T0_3B; module:encoder; layer:0; n_components: 3; variance explained: [0.91322815 0.00506137 0.00405438]\n",
      "0.9223439\n",
      "\n",
      "\n",
      "layer= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4776.25it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4792.64it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5847.68it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 6017.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:1; n_components: 1; variance explained: [0.23550335]\n",
      "0.23550335\n",
      "model:bigscience-T0_3B; module:encoder; layer:1; n_components: 2; variance explained: [0.23550317 0.1462696 ]\n",
      "0.38177276\n",
      "model:bigscience-T0_3B; module:encoder; layer:1; n_components: 3; variance explained: [0.2355033  0.14626974 0.07257798]\n",
      "0.45435104\n",
      "\n",
      "\n",
      "layer= 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4306.36it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5644.22it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5593.19it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5748.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:2; n_components: 1; variance explained: [0.98407835]\n",
      "0.98407835\n",
      "model:bigscience-T0_3B; module:encoder; layer:2; n_components: 2; variance explained: [0.9840782  0.00883231]\n",
      "0.99291056\n",
      "model:bigscience-T0_3B; module:encoder; layer:2; n_components: 3; variance explained: [0.98407835 0.00883231 0.00141225]\n",
      "0.99432296\n",
      "\n",
      "\n",
      "layer= 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4360.72it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5231.38it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5754.87it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5847.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:3; n_components: 1; variance explained: [0.9844427]\n",
      "0.9844427\n",
      "model:bigscience-T0_3B; module:encoder; layer:3; n_components: 2; variance explained: [0.9844427  0.00712584]\n",
      "0.99156857\n",
      "model:bigscience-T0_3B; module:encoder; layer:3; n_components: 3; variance explained: [0.98444253 0.00712583 0.0031549 ]\n",
      "0.99472326\n",
      "\n",
      "\n",
      "layer= 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4462.78it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5593.05it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5810.10it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5516.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:4; n_components: 1; variance explained: [0.98475385]\n",
      "0.98475385\n",
      "model:bigscience-T0_3B; module:encoder; layer:4; n_components: 2; variance explained: [0.9847539  0.00614626]\n",
      "0.99090016\n",
      "model:bigscience-T0_3B; module:encoder; layer:4; n_components: 3; variance explained: [0.9847539  0.00614626 0.00322178]\n",
      "0.9941219\n",
      "\n",
      "\n",
      "layer= 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4738.80it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4725.22it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5487.88it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5907.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:5; n_components: 1; variance explained: [0.984645]\n",
      "0.984645\n",
      "model:bigscience-T0_3B; module:encoder; layer:5; n_components: 2; variance explained: [0.984645   0.00564387]\n",
      "0.99028885\n",
      "model:bigscience-T0_3B; module:encoder; layer:5; n_components: 3; variance explained: [0.984645   0.00564387 0.00303771]\n",
      "0.99332654\n",
      "\n",
      "\n",
      "layer= 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4479.28it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5558.51it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5962.59it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5387.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:6; n_components: 1; variance explained: [0.9991639]\n",
      "0.9991639\n",
      "model:bigscience-T0_3B; module:encoder; layer:6; n_components: 2; variance explained: [9.9916410e-01 3.9299193e-04]\n",
      "0.9995571\n",
      "model:bigscience-T0_3B; module:encoder; layer:6; n_components: 3; variance explained: [9.9916393e-01 3.9299173e-04 1.3002341e-04]\n",
      "0.9996869\n",
      "\n",
      "\n",
      "layer= 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4422.18it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4575.04it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5452.13it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5896.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:7; n_components: 1; variance explained: [0.9990618]\n",
      "0.9990618\n",
      "model:bigscience-T0_3B; module:encoder; layer:7; n_components: 2; variance explained: [9.9906200e-01 3.8983574e-04]\n",
      "0.9994518\n",
      "model:bigscience-T0_3B; module:encoder; layer:7; n_components: 3; variance explained: [9.9906200e-01 3.8983574e-04 1.4156556e-04]\n",
      "0.9995934\n",
      "\n",
      "\n",
      "layer= 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4086.92it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5492.29it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5927.45it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5832.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:8; n_components: 1; variance explained: [0.9989372]\n",
      "0.9989372\n",
      "model:bigscience-T0_3B; module:encoder; layer:8; n_components: 2; variance explained: [9.9893719e-01 3.8038552e-04]\n",
      "0.9993176\n",
      "model:bigscience-T0_3B; module:encoder; layer:8; n_components: 3; variance explained: [9.9893719e-01 3.8038546e-04 1.6636155e-04]\n",
      "0.99948394\n",
      "\n",
      "\n",
      "layer= 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4834.52it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5272.62it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5765.84it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5811.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:9; n_components: 1; variance explained: [0.99873495]\n",
      "0.99873495\n",
      "model:bigscience-T0_3B; module:encoder; layer:9; n_components: 2; variance explained: [9.987352e-01 3.638970e-04]\n",
      "0.9990991\n",
      "model:bigscience-T0_3B; module:encoder; layer:9; n_components: 3; variance explained: [9.9873495e-01 3.6389683e-04 1.8174316e-04]\n",
      "0.9992806\n",
      "\n",
      "\n",
      "layer= 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4680.56it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5463.85it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5031.65it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5665.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:10; n_components: 1; variance explained: [0.9984353]\n",
      "0.9984353\n",
      "model:bigscience-T0_3B; module:encoder; layer:10; n_components: 2; variance explained: [9.984353e-01 3.522909e-04]\n",
      "0.9987876\n",
      "model:bigscience-T0_3B; module:encoder; layer:10; n_components: 3; variance explained: [9.9843538e-01 3.5229087e-04 2.1666016e-04]\n",
      "0.9990043\n",
      "\n",
      "\n",
      "layer= 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4241.37it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5244.94it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5129.16it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5872.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:11; n_components: 1; variance explained: [0.99799776]\n",
      "0.99799776\n",
      "model:bigscience-T0_3B; module:encoder; layer:11; n_components: 2; variance explained: [9.9799776e-01 3.6162260e-04]\n",
      "0.9983594\n",
      "model:bigscience-T0_3B; module:encoder; layer:11; n_components: 3; variance explained: [9.9799776e-01 3.6162321e-04 2.5670766e-04]\n",
      "0.9986161\n",
      "\n",
      "\n",
      "layer= 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4770.95it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5332.08it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5481.77it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5861.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:12; n_components: 1; variance explained: [0.9974137]\n",
      "0.9974137\n",
      "model:bigscience-T0_3B; module:encoder; layer:12; n_components: 2; variance explained: [9.974137e-01 3.982121e-04]\n",
      "0.9978119\n",
      "model:bigscience-T0_3B; module:encoder; layer:12; n_components: 3; variance explained: [9.9741369e-01 3.9821208e-04 3.2914008e-04]\n",
      "0.99814105\n",
      "\n",
      "\n",
      "layer= 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4376.27it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4417.69it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4533.00it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5042.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:13; n_components: 1; variance explained: [0.99639964]\n",
      "0.99639964\n",
      "model:bigscience-T0_3B; module:encoder; layer:13; n_components: 2; variance explained: [9.9639964e-01 4.9196638e-04]\n",
      "0.9968916\n",
      "model:bigscience-T0_3B; module:encoder; layer:13; n_components: 3; variance explained: [9.9639964e-01 4.9196591e-04 4.0927320e-04]\n",
      "0.99730086\n",
      "\n",
      "\n",
      "layer= 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4212.51it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5083.96it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4852.07it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5113.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:14; n_components: 1; variance explained: [0.9953063]\n",
      "0.9953063\n",
      "model:bigscience-T0_3B; module:encoder; layer:14; n_components: 2; variance explained: [9.9530613e-01 5.6844129e-04]\n",
      "0.9958746\n",
      "model:bigscience-T0_3B; module:encoder; layer:14; n_components: 3; variance explained: [9.9530613e-01 5.6844100e-04 4.7438726e-04]\n",
      "0.996349\n",
      "\n",
      "\n",
      "layer= 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4540.44it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5599.57it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5688.35it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5967.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:15; n_components: 1; variance explained: [0.9937378]\n",
      "0.9937378\n",
      "model:bigscience-T0_3B; module:encoder; layer:15; n_components: 2; variance explained: [9.9373782e-01 7.2730036e-04]\n",
      "0.9944651\n",
      "model:bigscience-T0_3B; module:encoder; layer:15; n_components: 3; variance explained: [9.9373782e-01 7.2729954e-04 6.1524642e-04]\n",
      "0.99508035\n",
      "\n",
      "\n",
      "layer= 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4571.98it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5631.00it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5404.68it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5836.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:16; n_components: 1; variance explained: [0.99143434]\n",
      "0.99143434\n",
      "model:bigscience-T0_3B; module:encoder; layer:16; n_components: 2; variance explained: [9.9143434e-01 9.6437294e-04]\n",
      "0.9923987\n",
      "model:bigscience-T0_3B; module:encoder; layer:16; n_components: 3; variance explained: [9.9143434e-01 9.6437469e-04 7.7617809e-04]\n",
      "0.9931749\n",
      "\n",
      "\n",
      "layer= 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4399.38it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4574.05it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5695.93it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4665.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:17; n_components: 1; variance explained: [0.98748666]\n",
      "0.98748666\n",
      "model:bigscience-T0_3B; module:encoder; layer:17; n_components: 2; variance explained: [0.98748666 0.00158377]\n",
      "0.9890704\n",
      "model:bigscience-T0_3B; module:encoder; layer:17; n_components: 3; variance explained: [0.98748666 0.00158377 0.00117682]\n",
      "0.99024725\n",
      "\n",
      "\n",
      "layer= 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4782.11it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5292.58it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5874.46it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5747.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:18; n_components: 1; variance explained: [0.9823134]\n",
      "0.9823134\n",
      "model:bigscience-T0_3B; module:encoder; layer:18; n_components: 2; variance explained: [0.9823134  0.00232101]\n",
      "0.9846344\n",
      "model:bigscience-T0_3B; module:encoder; layer:18; n_components: 3; variance explained: [0.9823134  0.00232101 0.00171001]\n",
      "0.9863444\n",
      "\n",
      "\n",
      "layer= 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4707.51it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4983.22it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5733.15it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5845.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:19; n_components: 1; variance explained: [0.9761332]\n",
      "0.9761332\n",
      "model:bigscience-T0_3B; module:encoder; layer:19; n_components: 2; variance explained: [0.9761332  0.00284858]\n",
      "0.9789818\n",
      "model:bigscience-T0_3B; module:encoder; layer:19; n_components: 3; variance explained: [0.9761332  0.00284858 0.00250812]\n",
      "0.9814899\n",
      "\n",
      "\n",
      "layer= 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4032.14it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4330.08it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5726.59it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5558.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:20; n_components: 1; variance explained: [0.967927]\n",
      "0.967927\n",
      "model:bigscience-T0_3B; module:encoder; layer:20; n_components: 2; variance explained: [0.9679273  0.00359196]\n",
      "0.97151923\n",
      "model:bigscience-T0_3B; module:encoder; layer:20; n_components: 3; variance explained: [0.967927   0.00359196 0.00318143]\n",
      "0.9747004\n",
      "\n",
      "\n",
      "layer= 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4763.64it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5560.61it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5855.93it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5773.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:21; n_components: 1; variance explained: [0.95778]\n",
      "0.95778\n",
      "model:bigscience-T0_3B; module:encoder; layer:21; n_components: 2; variance explained: [0.95778    0.00456588]\n",
      "0.9623459\n",
      "model:bigscience-T0_3B; module:encoder; layer:21; n_components: 3; variance explained: [0.95778    0.00456589 0.00435708]\n",
      "0.966703\n",
      "\n",
      "\n",
      "layer= 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4790.96it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5326.33it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5707.32it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5924.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:22; n_components: 1; variance explained: [0.9403951]\n",
      "0.9403951\n",
      "model:bigscience-T0_3B; module:encoder; layer:22; n_components: 2; variance explained: [0.9403951  0.00650239]\n",
      "0.9468975\n",
      "model:bigscience-T0_3B; module:encoder; layer:22; n_components: 3; variance explained: [0.9403951  0.00650239 0.00546497]\n",
      "0.9523625\n",
      "\n",
      "\n",
      "layer= 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5000.66it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5199.08it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5653.58it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5815.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:23; n_components: 1; variance explained: [0.9159726]\n",
      "0.9159726\n",
      "model:bigscience-T0_3B; module:encoder; layer:23; n_components: 2; variance explained: [0.9159724  0.00843732]\n",
      "0.92440975\n",
      "model:bigscience-T0_3B; module:encoder; layer:23; n_components: 3; variance explained: [0.9159724  0.00843733 0.00724282]\n",
      "0.93165255\n",
      "\n",
      "\n",
      "layer= 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4437.55it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4514.30it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5476.91it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5802.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 2048) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0_3B; module:encoder; layer:24; n_components: 1; variance explained: [0.05968468]\n",
      "0.05968468\n",
      "model:bigscience-T0_3B; module:encoder; layer:24; n_components: 2; variance explained: [0.05968472 0.05574055]\n",
      "0.115425274\n",
      "model:bigscience-T0_3B; module:encoder; layer:24; n_components: 3; variance explained: [0.05968466 0.0557405  0.05277915]\n",
      "0.16820432\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for layer in range(0, 10):\n",
    "for layer in range(0, 25):\n",
    "# for layer in range(24, 25):\n",
    "    print('layer=', layer)\n",
    "    file_names, prompt_names = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if row['name'] in use_pattern:\n",
    "            file_names.append(f\"{task}/{model}/{module}/{row['name']}/hidden_represenations_layer{layer}_avg.hdf5\",)\n",
    "            prompt_names.append(row['name'])\n",
    "\n",
    "\n",
    "    # load hidden representations from hdf5 file\n",
    "    representations = None\n",
    "    classes = []\n",
    "    n_sequences = 0\n",
    "\n",
    "    for idx, file_name in enumerate(file_names):\n",
    "        hidden_representations = load_hidden_representations_from_hdf5(os.path.join(log_dir, file_name))\n",
    "        # print(hidden_representations.shape)\n",
    "        n_sequences = hidden_representations.shape[0]\n",
    "\n",
    "        if representations is None:\n",
    "            representations = hidden_representations\n",
    "        else:\n",
    "            representations = np.concatenate((representations, hidden_representations), axis=0)\n",
    "\n",
    "        classes += n_sequences * [idx] # assign representations to classes\n",
    "    \n",
    "    classes = np.asarray(classes)\n",
    "\n",
    "    # shuffle representations and classes\n",
    "    X, y = unison_shuffled_copies(representations, classes)\n",
    "    print(X.shape, y.shape)\n",
    "\n",
    "    # perform PCA on hidden representations\n",
    "    print('PCA for prompts:', prompt_names)\n",
    "\n",
    "    for n_components in range(1, 4):\n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca.fit(X)\n",
    "\n",
    "        # variance explained by each of the principal components\n",
    "        print(f\"model:{model}; module:{module}; layer:{layer}; n_components: {n_components}; variance explained: {pca.explained_variance_ratio_}\")\n",
    "        print(np.sum(pca.explained_variance_ratio_))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
