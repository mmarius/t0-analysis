{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from utils import load_hidden_representations_from_hdf5, read_templates_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "log_dir = \"/logfiles\"\n",
    "model = \"bigscience-T0_3B\" # bigscience-T0_B or bigscience-T0\n",
    "module = \"encoder\" # encoder or decoder\n",
    "task = \"rte\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>template</th>\n",
       "      <th>category</th>\n",
       "      <th>shuffle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null_pattern</td>\n",
       "      <td>{premise} {hypothesis}</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>null_pattern_reversed</td>\n",
       "      <td>{hypothesis} {premise}</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt_3_yes_no</td>\n",
       "      <td>{premise} Question: {hypothesis} Yes or No?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt_3_yes_no_shuffled</td>\n",
       "      <td>{premise} Question: {hypothesis} Yes or No?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt_3_true_false</td>\n",
       "      <td>{premise} Question: {hypothesis} True or False?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt_3_true_false_shuffled</td>\n",
       "      <td>{premise} Question: {hypothesis} True or False?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>start_with_the</td>\n",
       "      <td>{premise} Does the paragraph start with \"the\"?...</td>\n",
       "      <td>misleading</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mnli_crowdsource</td>\n",
       "      <td>{premise} Using only the above description and...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>based_on_previous_passage</td>\n",
       "      <td>{premise} Based on the previous passage; is it...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>infer</td>\n",
       "      <td>Suppose {premise} Can we infer that \"{hypothes...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>follow</td>\n",
       "      <td>Given that {premise} Does it follow that {hypo...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>imply</td>\n",
       "      <td>{premise} Question: Does this imply that \"{hyp...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>guaranteed</td>\n",
       "      <td>Given {premise} Is it guaranteed true that \"{h...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>justified</td>\n",
       "      <td>{premise} Are we justified in saying that \"{hy...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>must_be_true</td>\n",
       "      <td>Given that {premise} Therefore it must be true...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>should_assume</td>\n",
       "      <td>Given {premise} Should we assume that \"{hypoth...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name  \\\n",
       "0                null_pattern   \n",
       "1       null_pattern_reversed   \n",
       "2                gpt_3_yes_no   \n",
       "3       gpt_3_yes_no_shuffled   \n",
       "4            gpt_3_true_false   \n",
       "5   gpt_3_true_false_shuffled   \n",
       "6              start_with_the   \n",
       "7            mnli_crowdsource   \n",
       "8   based_on_previous_passage   \n",
       "9                       infer   \n",
       "10                     follow   \n",
       "11                      imply   \n",
       "12                 guaranteed   \n",
       "13                  justified   \n",
       "14               must_be_true   \n",
       "15              should_assume   \n",
       "\n",
       "                                             template     category  shuffle  \n",
       "0                              {premise} {hypothesis}      neutral    False  \n",
       "1                              {hypothesis} {premise}      neutral    False  \n",
       "2         {premise} Question: {hypothesis} Yes or No?  instructive    False  \n",
       "3         {premise} Question: {hypothesis} Yes or No?  instructive     True  \n",
       "4     {premise} Question: {hypothesis} True or False?  instructive    False  \n",
       "5     {premise} Question: {hypothesis} True or False?  instructive     True  \n",
       "6   {premise} Does the paragraph start with \"the\"?...   misleading    False  \n",
       "7   {premise} Using only the above description and...  instructive    False  \n",
       "8   {premise} Based on the previous passage; is it...  instructive    False  \n",
       "9   Suppose {premise} Can we infer that \"{hypothes...  instructive    False  \n",
       "10  Given that {premise} Does it follow that {hypo...  instructive    False  \n",
       "11  {premise} Question: Does this imply that \"{hyp...  instructive    False  \n",
       "12  Given {premise} Is it guaranteed true that \"{h...  instructive    False  \n",
       "13  {premise} Are we justified in saying that \"{hy...  instructive    False  \n",
       "14  Given that {premise} Therefore it must be true...  instructive    False  \n",
       "15  Given {premise} Should we assume that \"{hypoth...  instructive    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read_templates_from_file(f\"/t0-analysis/prompts/{task}.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    # from: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which patterns to use for classification\n",
    "use_pattern = [\n",
    "    # \"null_pattern\",\n",
    "    # \"null_pattern_reversed\",\n",
    "    \"gpt_3_yes_no\",\n",
    "    # \"gpt_3_yes_no_shuffled\",\n",
    "    # \"gpt_3_true_false\",\n",
    "    # \"gpt_3_true_false_shuffled\",\n",
    "    # \"start_with_the\",\n",
    "    # \"mnli_crowdsource\",\n",
    "    # \"based_on_previous_passage\",\n",
    "    # \"infer\",\n",
    "    # \"follow\",\n",
    "    # \"imply\",\n",
    "    # \"guaranteed\",\n",
    "    # \"justified\", \n",
    "    # \"must_be_true\",\n",
    "    \"should_assume\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4944.81it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4980.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 2048) (554,)\n",
      "PCA for prompts: ['gpt_3_yes_no', 'should_assume']\n",
      "model:bigscience-T0_3B; module:encoder; layer:0; n_components: 1; variance explained: [0.9136936]\n",
      "0.9136936\n",
      "model:bigscience-T0_3B; module:encoder; layer:0; n_components: 2; variance explained: [0.91369355 0.00523294]\n",
      "0.9189265\n",
      "model:bigscience-T0_3B; module:encoder; layer:0; n_components: 3; variance explained: [0.91369355 0.00523293 0.00414104]\n",
      "0.9230675\n",
      "model:bigscience-T0_3B; module:encoder; layer:0; n_components: 4; variance explained: [0.9136936  0.00523293 0.00414104 0.00295302]\n",
      "0.92602056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3254.87it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4826.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 2048) (554,)\n",
      "PCA for prompts: ['gpt_3_yes_no', 'should_assume']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:bigscience-T0_3B; module:encoder; layer:1; n_components: 1; variance explained: [0.27057573]\n",
      "0.27057573\n",
      "model:bigscience-T0_3B; module:encoder; layer:1; n_components: 2; variance explained: [0.27057573 0.1344223 ]\n",
      "0.40499803\n",
      "model:bigscience-T0_3B; module:encoder; layer:1; n_components: 3; variance explained: [0.27057573 0.13442223 0.06982672]\n",
      "0.47482467\n",
      "model:bigscience-T0_3B; module:encoder; layer:1; n_components: 4; variance explained: [0.27057582 0.13442232 0.06982674 0.06634006]\n",
      "0.5411649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3227.63it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4905.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 2048) (554,)\n",
      "PCA for prompts: ['gpt_3_yes_no', 'should_assume']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:bigscience-T0_3B; module:encoder; layer:2; n_components: 1; variance explained: [0.98539364]\n",
      "0.98539364\n",
      "model:bigscience-T0_3B; module:encoder; layer:2; n_components: 2; variance explained: [0.98539364 0.00834502]\n",
      "0.99373865\n",
      "model:bigscience-T0_3B; module:encoder; layer:2; n_components: 3; variance explained: [0.98539364 0.00834502 0.00127365]\n",
      "0.9950123\n",
      "model:bigscience-T0_3B; module:encoder; layer:2; n_components: 4; variance explained: [9.8539364e-01 8.3450228e-03 1.2736472e-03 8.5487531e-04]\n",
      "0.99586713\n"
     ]
    }
   ],
   "source": [
    "for layer in range(0, 3):\n",
    "# for layer in range(0, 25):\n",
    "# for layer in range(24, 25):\n",
    "\n",
    "    file_names, prompt_names = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if row['name'] in use_pattern:\n",
    "            file_names.append(f\"rte/{model}/{module}/{row['name']}/hidden_represenations_layer{layer}_avg.hdf5\",)\n",
    "            prompt_names.append(row['name'])\n",
    "\n",
    "\n",
    "    # load hidden representations from hdf5 file\n",
    "    representations = None\n",
    "    classes = []\n",
    "    n_sequences = 0\n",
    "\n",
    "    for idx, file_name in enumerate(file_names):\n",
    "        hidden_representations = load_hidden_representations_from_hdf5(os.path.join(log_dir, file_name))\n",
    "        # print(hidden_representations.shape)\n",
    "        n_sequences = hidden_representations.shape[0]\n",
    "\n",
    "        if representations is None:\n",
    "            representations = hidden_representations\n",
    "        else:\n",
    "            representations = np.concatenate((representations, hidden_representations), axis=0)\n",
    "\n",
    "        classes += n_sequences * [idx] # assign representations to classes\n",
    "    \n",
    "    classes = np.asarray(classes)\n",
    "\n",
    "    # shuffle representations and classes\n",
    "    X, y = unison_shuffled_copies(representations, classes)\n",
    "    print(X.shape, y.shape)\n",
    "\n",
    "    # perform PCA on hidden representations\n",
    "    print('PCA for prompts:', prompt_names)\n",
    "\n",
    "    for n_components in range(1, 5):\n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca.fit(X)\n",
    "\n",
    "        # variance explained by each of the principal components\n",
    "        print(f\"model:{model}; module:{module}; layer:{layer}; n_components: {n_components}; variance explained: {pca.explained_variance_ratio_}\")\n",
    "        print(np.sum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
