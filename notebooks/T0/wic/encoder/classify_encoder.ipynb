{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from utils import load_hidden_representations_from_hdf5, read_templates_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "log_dir = \"/logfiles\"\n",
    "model = \"bigscience-T0\"\n",
    "module = \"encoder\"\n",
    "task = \"wic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions\n",
    "assert model == \"bigscience-T0\"\n",
    "assert module == \"encoder\"\n",
    "assert task == \"wic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>template</th>\n",
       "      <th>category</th>\n",
       "      <th>includes_targets</th>\n",
       "      <th>targets</th>\n",
       "      <th>target_ids</th>\n",
       "      <th>shuffle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_3_without_targets</td>\n",
       "      <td>{sentence1} {sentence2} Question: Is the word ...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "      <td>▁No, ▁no, ▁Yes, ▁yes</td>\n",
       "      <td>0, 0, 1, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt_3_yes_no_with_targets</td>\n",
       "      <td>{sentence1} {sentence2} Question: Is the word ...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁No, ▁Yes</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>affirmation_with_targets</td>\n",
       "      <td>Sentence A: {sentence1} Sentence B: {sentence2...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Fal, ▁True</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grammar_homework_with_targets</td>\n",
       "      <td>Decide whether the word \"{word}\" is used with ...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁No, ▁Yes</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>polysemous_with_targets</td>\n",
       "      <td>The word \"{word}\" has multiple meanings. Does ...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁No, ▁Yes</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>question_context_without_targets</td>\n",
       "      <td>Determine if the word \"{word}\" is used in the ...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "      <td>▁No, ▁no, ▁Yes, ▁yes</td>\n",
       "      <td>0, 0, 1, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>question_meaning_without_targets</td>\n",
       "      <td>Determine if the word \"{word}\" have the same m...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "      <td>▁No, ▁no, ▁Yes, ▁yes</td>\n",
       "      <td>0, 0, 1, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>question_meaning_yes_no_with_targets</td>\n",
       "      <td>Does the word \"{word}\" have the same meanining...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁No, ▁Yes</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>same_sense_with_targets</td>\n",
       "      <td>Sentence 1: {sentence1} Sentence 2: {sentence2...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁No, ▁Yes</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>similar_sense_without_targets</td>\n",
       "      <td>{sentence1} {sentence2} Similar sense of {word}?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "      <td>▁No, ▁no, ▁Yes, ▁yes</td>\n",
       "      <td>0, 0, 1, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>similar_sense_yes_no_with_targets</td>\n",
       "      <td>{sentence1} {sentence2} Similar sense of {word...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁No, ▁Yes</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt_3_true_false_with_targets</td>\n",
       "      <td>{sentence1} {sentence2} Question: Is the word ...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Fal, ▁True</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt_3_cat_dog_with_targets</td>\n",
       "      <td>{sentence1} {sentence2} Question: Is the word ...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Cat, ▁Dog</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name  \\\n",
       "0                  gpt_3_without_targets   \n",
       "1              gpt_3_yes_no_with_targets   \n",
       "2               affirmation_with_targets   \n",
       "3          grammar_homework_with_targets   \n",
       "4                polysemous_with_targets   \n",
       "5       question_context_without_targets   \n",
       "6       question_meaning_without_targets   \n",
       "7   question_meaning_yes_no_with_targets   \n",
       "8                same_sense_with_targets   \n",
       "9          similar_sense_without_targets   \n",
       "10     similar_sense_yes_no_with_targets   \n",
       "11         gpt_3_true_false_with_targets   \n",
       "12            gpt_3_cat_dog_with_targets   \n",
       "\n",
       "                                             template     category  \\\n",
       "0   {sentence1} {sentence2} Question: Is the word ...  instructive   \n",
       "1   {sentence1} {sentence2} Question: Is the word ...  instructive   \n",
       "2   Sentence A: {sentence1} Sentence B: {sentence2...  instructive   \n",
       "3   Decide whether the word \"{word}\" is used with ...  instructive   \n",
       "4   The word \"{word}\" has multiple meanings. Does ...  instructive   \n",
       "5   Determine if the word \"{word}\" is used in the ...  instructive   \n",
       "6   Determine if the word \"{word}\" have the same m...  instructive   \n",
       "7   Does the word \"{word}\" have the same meanining...  instructive   \n",
       "8   Sentence 1: {sentence1} Sentence 2: {sentence2...  instructive   \n",
       "9    {sentence1} {sentence2} Similar sense of {word}?  instructive   \n",
       "10  {sentence1} {sentence2} Similar sense of {word...  instructive   \n",
       "11  {sentence1} {sentence2} Question: Is the word ...  instructive   \n",
       "12  {sentence1} {sentence2} Question: Is the word ...  instructive   \n",
       "\n",
       "    includes_targets               targets  target_ids  shuffle  \n",
       "0              False  ▁No, ▁no, ▁Yes, ▁yes  0, 0, 1, 1    False  \n",
       "1               True             ▁No, ▁Yes        0, 1    False  \n",
       "2               True           ▁Fal, ▁True        0, 1    False  \n",
       "3               True             ▁No, ▁Yes        0, 1    False  \n",
       "4               True             ▁No, ▁Yes        0, 1    False  \n",
       "5              False  ▁No, ▁no, ▁Yes, ▁yes  0, 0, 1, 1    False  \n",
       "6              False  ▁No, ▁no, ▁Yes, ▁yes  0, 0, 1, 1    False  \n",
       "7               True             ▁No, ▁Yes        0, 1    False  \n",
       "8               True             ▁No, ▁Yes        0, 1    False  \n",
       "9              False  ▁No, ▁no, ▁Yes, ▁yes  0, 0, 1, 1    False  \n",
       "10              True             ▁No, ▁Yes        0, 1    False  \n",
       "11              True           ▁Fal, ▁True        0, 1    False  \n",
       "12              True            ▁Cat, ▁Dog        0, 1    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/all.csv\")\n",
    "# df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/fixed_prompt.csv\")\n",
    "# df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/fixed_target_yes_no.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    # from: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pattern = [\n",
    "    # \"gpt_3_without_targets\",\n",
    "    \"gpt_3_yes_no_with_targets\",\n",
    "    # \"affirmation_with_targets\",\n",
    "    # \"grammar_homework_with_targets\",\n",
    "    # \"polysemous_with_targets\",\n",
    "    # \"question_context_without_targets\",\n",
    "    # \"question_meaning_without_targets\",\n",
    "    # \"question_meaning_yes_no_with_targets\",\n",
    "    # \"same_sense_with_targets\",\n",
    "    # \"similar_sense_without_targets\",\n",
    "    # \"similar_sense_yes_no_with_targets\",\n",
    "    \"gpt_3_true_false_with_targets\",\n",
    "    # \"gpt_3_cat_dog_with_targets\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4036.42it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5911.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=0; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5138.42it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5918.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=1; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4136.81it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5867.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=2; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4762.23it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5801.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=3; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4808.37it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5820.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=4; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4813.15it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5589.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=5; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4743.80it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5091.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=6; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4929.88it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5419.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=7; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4880.70it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5965.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=8; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4883.78it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5825.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=9; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4926.44it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5969.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=10; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4929.04it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5312.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=11; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4241.88it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5730.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=12; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4305.00it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5969.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=13; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5018.50it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 6088.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=14; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4872.06it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 6030.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=15; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4959.01it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5900.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=16; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4946.17it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5915.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=17; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4843.23it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5971.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=18; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4642.26it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5785.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=19; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4277.69it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 6042.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=20; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4940.68it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5694.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=21; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5039.18it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 6097.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=22; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 5080.71it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 6028.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=23; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 4901.57it/s]\n",
      "Reading embeddings: 100%|██████████| 638/638 [00:00<00:00, 6072.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 4096) (1276,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n",
      "layer=24; accuracy on training data:  0.9992163009404389\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for layer in range(0, 10):\n",
    "for layer in range(0, 25):\n",
    "# for layer in range(24, 25):\n",
    "    \n",
    "    print(\"layer:\", layer)\n",
    "    file_names, prompt_names = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if row['name'] in use_pattern:\n",
    "            file_names.append(f\"{task}/{model}/{module}/{row['name']}/hidden_represenations_layer{layer}_avg.hdf5\",)\n",
    "            prompt_names.append(row['name'])\n",
    "\n",
    "    # load hidden representations from hdf5 file\n",
    "    representations = None\n",
    "    classes = []\n",
    "    n_sequences = 0\n",
    "\n",
    "    for idx, file_name in enumerate(file_names):\n",
    "        hidden_representations = load_hidden_representations_from_hdf5(os.path.join(log_dir, file_name))\n",
    "        # print(hidden_representations.shape)\n",
    "        n_sequences = hidden_representations.shape[0]\n",
    "\n",
    "        if representations is None:\n",
    "            representations = hidden_representations\n",
    "        else:\n",
    "            representations = np.concatenate((representations, hidden_representations), axis=0)\n",
    "\n",
    "        classes += n_sequences * [idx] # assign representations to classes\n",
    "    \n",
    "    classes = np.asarray(classes)\n",
    "\n",
    "    # shuffle representations and classes\n",
    "    X, y = unison_shuffled_copies(representations, classes)\n",
    "    print(X.shape, y.shape)\n",
    "\n",
    "    # train linear classifier\n",
    "    # multi_class='multinomial' uses a CE loss\n",
    "    print('classifying between:', prompt_names)\n",
    "    clf = LogisticRegression(random_state=0, max_iter=2000, multi_class='multinomial').fit(X, y)\n",
    "    \n",
    "    print(f'layer={layer}; accuracy on training data: ', clf.score(X, y))\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
