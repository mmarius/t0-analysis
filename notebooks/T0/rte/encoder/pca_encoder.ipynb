{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from utils import load_hidden_representations_from_hdf5, read_templates_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "log_dir = \"/logfiles\"\n",
    "model = \"bigscience-T0\"\n",
    "module = \"encoder\" # encoder\n",
    "task = \"rte\"\n",
    "# task = \"cb\"\n",
    "# task = \"wic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert module == \"encoder\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>template</th>\n",
       "      <th>category</th>\n",
       "      <th>includes_targets</th>\n",
       "      <th>targets</th>\n",
       "      <th>target_ids</th>\n",
       "      <th>shuffle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_3_yes_no_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} Yes or No?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt_3_true_false_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} True or False?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁True, ▁Fal</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt_3_cat_dog_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} Cat or Dog?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Cat, ▁Dog</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt_3_yes_no_without_targets</td>\n",
       "      <td>{premise} Question: {hypothesis}?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  \\\n",
       "0      gpt_3_yes_no_with_targets   \n",
       "1  gpt_3_true_false_with_targets   \n",
       "2     gpt_3_cat_dog_with_targets   \n",
       "3   gpt_3_yes_no_without_targets   \n",
       "\n",
       "                                          template     category  \\\n",
       "0      {premise} Question: {hypothesis} Yes or No?  instructive   \n",
       "1  {premise} Question: {hypothesis} True or False?  instructive   \n",
       "2     {premise} Question: {hypothesis} Cat or Dog?  instructive   \n",
       "3                {premise} Question: {hypothesis}?  instructive   \n",
       "\n",
       "   includes_targets      targets target_ids  shuffle  \n",
       "0              True    ▁Yes, ▁No       0, 1    False  \n",
       "1              True  ▁True, ▁Fal       0, 1    False  \n",
       "2              True   ▁Cat, ▁Dog       0, 1    False  \n",
       "3             False    ▁Yes, ▁No       0, 1    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/fixed_prompt.csv\")\n",
    "# df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/fixed_target_yes_no.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    # from: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == 'rte':\n",
    "    use_pattern = [\n",
    "        \"gpt_3_yes_no_with_targets\",\n",
    "        \"gpt_3_true_false_with_targets\",\n",
    "        \"gpt_3_cat_dog_with_targets\",\n",
    "        \"gpt_3_yes_no_without_targets\",\n",
    "    ]\n",
    "elif task == 'cb':\n",
    "    use_pattern = [\n",
    "        \"null_pattern\",\n",
    "        \"null_pattern_reversed\",\n",
    "        \"gpt_3_true_false_neither\",\n",
    "        \"gpt_3_yes_no_maybe\",\n",
    "        \"mnli_crowdsource\",\n",
    "        \"always_sometimes_never\",\n",
    "        \"based_on_previous_passage\",\n",
    "        \"infer\",\n",
    "        \"claim\",\n",
    "        \"consider\",\n",
    "        \"follow\",\n",
    "        \"imply\",\n",
    "        \"guaranteed\",\n",
    "        \"guaranteed_possible\",\n",
    "        \"justified\",\n",
    "        \"must_be_true\",\n",
    "        \"should_assume\",\n",
    "        \"take_the_following\",\n",
    "    ]\n",
    "elif task == 'wic':\n",
    "    use_pattern = [\n",
    "        \"gpt_3\",\n",
    "        \"gpt_3_yes_no\",\n",
    "        \"affirmation\",\n",
    "        \"grammar_homework\",\n",
    "        \"polysemous\",\n",
    "        \"question_context\",\n",
    "        \"question_meaning\",\n",
    "        \"question_meaning_yes_no\",\n",
    "        \"same_sense\",\n",
    "        \"similar_sense\",\n",
    "        \"similar_sense_yes_no\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5035.31it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5755.01it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5631.17it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5695.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:0; n_components: 1; variance explained: [0.9520281]\n",
      "0.9520281\n",
      "model:bigscience-T0; module:encoder; layer:0; n_components: 2; variance explained: [0.9520281  0.00233076]\n",
      "0.9543589\n",
      "model:bigscience-T0; module:encoder; layer:0; n_components: 3; variance explained: [0.95202833 0.00233076 0.00181649]\n",
      "0.9561756\n",
      "\n",
      "\n",
      "layer= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4326.42it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5445.77it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5190.76it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5511.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:1; n_components: 1; variance explained: [0.09682094]\n",
      "0.09682094\n",
      "model:bigscience-T0; module:encoder; layer:1; n_components: 2; variance explained: [0.09682087 0.06569661]\n",
      "0.16251749\n",
      "model:bigscience-T0; module:encoder; layer:1; n_components: 3; variance explained: [0.09682088 0.06569663 0.04756508]\n",
      "0.2100826\n",
      "\n",
      "\n",
      "layer= 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4512.96it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5302.05it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5272.65it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5823.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:2; n_components: 1; variance explained: [0.09697562]\n",
      "0.096975625\n",
      "model:bigscience-T0; module:encoder; layer:2; n_components: 2; variance explained: [0.09697556 0.05690577]\n",
      "0.15388134\n",
      "model:bigscience-T0; module:encoder; layer:2; n_components: 3; variance explained: [0.09697556 0.0569058  0.04918922]\n",
      "0.2030706\n",
      "\n",
      "\n",
      "layer= 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4421.44it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5569.94it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5789.74it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5781.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:3; n_components: 1; variance explained: [0.09449974]\n",
      "0.09449974\n",
      "model:bigscience-T0; module:encoder; layer:3; n_components: 2; variance explained: [0.09449969 0.05680556]\n",
      "0.15130526\n",
      "model:bigscience-T0; module:encoder; layer:3; n_components: 3; variance explained: [0.09449966 0.05680554 0.05114779]\n",
      "0.20245299\n",
      "\n",
      "\n",
      "layer= 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3980.27it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4788.47it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5715.49it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5649.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:4; n_components: 1; variance explained: [0.09955579]\n",
      "0.09955579\n",
      "model:bigscience-T0; module:encoder; layer:4; n_components: 2; variance explained: [0.09955579 0.05881744]\n",
      "0.15837324\n",
      "model:bigscience-T0; module:encoder; layer:4; n_components: 3; variance explained: [0.09955574 0.0588174  0.0526537 ]\n",
      "0.21102685\n",
      "\n",
      "\n",
      "layer= 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4409.93it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4613.77it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5646.35it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5817.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:5; n_components: 1; variance explained: [0.1027218]\n",
      "0.1027218\n",
      "model:bigscience-T0; module:encoder; layer:5; n_components: 2; variance explained: [0.10272174 0.05728566]\n",
      "0.1600074\n",
      "model:bigscience-T0; module:encoder; layer:5; n_components: 3; variance explained: [0.10272174 0.05728569 0.05561144]\n",
      "0.21561886\n",
      "\n",
      "\n",
      "layer= 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3710.05it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5468.71it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5497.36it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5176.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:6; n_components: 1; variance explained: [0.11103139]\n",
      "0.11103139\n",
      "model:bigscience-T0; module:encoder; layer:6; n_components: 2; variance explained: [0.11103135 0.07536475]\n",
      "0.18639609\n",
      "model:bigscience-T0; module:encoder; layer:6; n_components: 3; variance explained: [0.11103138 0.07536465 0.05668331]\n",
      "0.24307933\n",
      "\n",
      "\n",
      "layer= 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3143.93it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5652.10it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5554.49it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4952.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:7; n_components: 1; variance explained: [0.11904773]\n",
      "0.11904773\n",
      "model:bigscience-T0; module:encoder; layer:7; n_components: 2; variance explained: [0.11904787 0.0875036 ]\n",
      "0.20655146\n",
      "model:bigscience-T0; module:encoder; layer:7; n_components: 3; variance explained: [0.11904795 0.08750377 0.05956649]\n",
      "0.26611823\n",
      "\n",
      "\n",
      "layer= 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4691.10it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5463.21it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5517.01it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5264.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:8; n_components: 1; variance explained: [0.13349755]\n",
      "0.13349755\n",
      "model:bigscience-T0; module:encoder; layer:8; n_components: 2; variance explained: [0.13349748 0.09660843]\n",
      "0.2301059\n",
      "model:bigscience-T0; module:encoder; layer:8; n_components: 3; variance explained: [0.13349755 0.09660858 0.06090045]\n",
      "0.29100657\n",
      "\n",
      "\n",
      "layer= 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4745.23it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4913.44it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5675.98it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5353.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:9; n_components: 1; variance explained: [0.14086504]\n",
      "0.14086504\n",
      "model:bigscience-T0; module:encoder; layer:9; n_components: 2; variance explained: [0.14086504 0.09994665]\n",
      "0.24081169\n",
      "model:bigscience-T0; module:encoder; layer:9; n_components: 3; variance explained: [0.14086503 0.09994655 0.06217516]\n",
      "0.30298674\n",
      "\n",
      "\n",
      "layer= 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4791.95it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4610.66it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5564.07it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5883.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:10; n_components: 1; variance explained: [0.1447299]\n",
      "0.1447299\n",
      "model:bigscience-T0; module:encoder; layer:10; n_components: 2; variance explained: [0.14472994 0.099124  ]\n",
      "0.24385394\n",
      "model:bigscience-T0; module:encoder; layer:10; n_components: 3; variance explained: [0.14472982 0.09912393 0.06749202]\n",
      "0.31134576\n",
      "\n",
      "\n",
      "layer= 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3367.24it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5647.26it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5890.25it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5501.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:11; n_components: 1; variance explained: [0.1552256]\n",
      "0.1552256\n",
      "model:bigscience-T0; module:encoder; layer:11; n_components: 2; variance explained: [0.15522563 0.0918576 ]\n",
      "0.24708325\n",
      "model:bigscience-T0; module:encoder; layer:11; n_components: 3; variance explained: [0.1552256  0.09185755 0.07376391]\n",
      "0.32084706\n",
      "\n",
      "\n",
      "layer= 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4403.94it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5397.02it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5775.41it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5797.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:12; n_components: 1; variance explained: [0.14382245]\n",
      "0.14382245\n",
      "model:bigscience-T0; module:encoder; layer:12; n_components: 2; variance explained: [0.14382239 0.10314302]\n",
      "0.24696541\n",
      "model:bigscience-T0; module:encoder; layer:12; n_components: 3; variance explained: [0.1438223  0.10314307 0.0782585 ]\n",
      "0.32522386\n",
      "\n",
      "\n",
      "layer= 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4681.92it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5659.14it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5597.71it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4839.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:13; n_components: 1; variance explained: [0.16771707]\n",
      "0.16771707\n",
      "model:bigscience-T0; module:encoder; layer:13; n_components: 2; variance explained: [0.16771716 0.1162237 ]\n",
      "0.28394085\n",
      "model:bigscience-T0; module:encoder; layer:13; n_components: 3; variance explained: [0.16771722 0.1162239  0.08643428]\n",
      "0.3703754\n",
      "\n",
      "\n",
      "layer= 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4625.97it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4794.52it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4825.00it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5884.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:14; n_components: 1; variance explained: [0.16685796]\n",
      "0.16685796\n",
      "model:bigscience-T0; module:encoder; layer:14; n_components: 2; variance explained: [0.16685797 0.12553056]\n",
      "0.29238853\n",
      "model:bigscience-T0; module:encoder; layer:14; n_components: 3; variance explained: [0.16685791 0.12553054 0.09177103]\n",
      "0.38415948\n",
      "\n",
      "\n",
      "layer= 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4194.73it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5929.24it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5663.12it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5591.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:15; n_components: 1; variance explained: [0.16473149]\n",
      "0.16473149\n",
      "model:bigscience-T0; module:encoder; layer:15; n_components: 2; variance explained: [0.16473149 0.12942521]\n",
      "0.2941567\n",
      "model:bigscience-T0; module:encoder; layer:15; n_components: 3; variance explained: [0.16473156 0.12942532 0.09364991]\n",
      "0.38780677\n",
      "\n",
      "\n",
      "layer= 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4355.85it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5605.76it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5927.51it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5997.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:16; n_components: 1; variance explained: [0.17510171]\n",
      "0.17510171\n",
      "model:bigscience-T0; module:encoder; layer:16; n_components: 2; variance explained: [0.17510174 0.12535547]\n",
      "0.3004572\n",
      "model:bigscience-T0; module:encoder; layer:16; n_components: 3; variance explained: [0.17510174 0.12535563 0.09488916]\n",
      "0.39534652\n",
      "\n",
      "\n",
      "layer= 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3912.18it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5821.72it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 6009.22it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5846.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:17; n_components: 1; variance explained: [0.19878805]\n",
      "0.19878805\n",
      "model:bigscience-T0; module:encoder; layer:17; n_components: 2; variance explained: [0.19878805 0.12251233]\n",
      "0.3213004\n",
      "model:bigscience-T0; module:encoder; layer:17; n_components: 3; variance explained: [0.19878808 0.12251228 0.08592755]\n",
      "0.4072279\n",
      "\n",
      "\n",
      "layer= 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4109.87it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5850.71it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5853.51it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5863.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:18; n_components: 1; variance explained: [0.21415678]\n",
      "0.21415678\n",
      "model:bigscience-T0; module:encoder; layer:18; n_components: 2; variance explained: [0.21415682 0.11573417]\n",
      "0.329891\n",
      "model:bigscience-T0; module:encoder; layer:18; n_components: 3; variance explained: [0.21415664 0.11573419 0.07649796]\n",
      "0.40638882\n",
      "\n",
      "\n",
      "layer= 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4871.00it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5196.75it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4531.94it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5155.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:19; n_components: 1; variance explained: [0.2091777]\n",
      "0.2091777\n",
      "model:bigscience-T0; module:encoder; layer:19; n_components: 2; variance explained: [0.20917766 0.12959088]\n",
      "0.33876854\n",
      "model:bigscience-T0; module:encoder; layer:19; n_components: 3; variance explained: [0.20917766 0.12959094 0.06195352]\n",
      "0.40072212\n",
      "\n",
      "\n",
      "layer= 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4539.70it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5528.85it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5238.13it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5741.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:20; n_components: 1; variance explained: [0.17561568]\n",
      "0.17561568\n",
      "model:bigscience-T0; module:encoder; layer:20; n_components: 2; variance explained: [0.17561574 0.14822227]\n",
      "0.323838\n",
      "model:bigscience-T0; module:encoder; layer:20; n_components: 3; variance explained: [0.17561565 0.14822221 0.06115665]\n",
      "0.38499454\n",
      "\n",
      "\n",
      "layer= 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4514.86it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5591.49it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5690.88it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5696.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:21; n_components: 1; variance explained: [0.16786753]\n",
      "0.16786753\n",
      "model:bigscience-T0; module:encoder; layer:21; n_components: 2; variance explained: [0.16786759 0.14820603]\n",
      "0.3160736\n",
      "model:bigscience-T0; module:encoder; layer:21; n_components: 3; variance explained: [0.16786753 0.1482061  0.05901549]\n",
      "0.3750891\n",
      "\n",
      "\n",
      "layer= 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4230.35it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4787.33it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5392.09it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5157.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:22; n_components: 1; variance explained: [0.18796729]\n",
      "0.18796729\n",
      "model:bigscience-T0; module:encoder; layer:22; n_components: 2; variance explained: [0.18796754 0.12157819]\n",
      "0.30954573\n",
      "model:bigscience-T0; module:encoder; layer:22; n_components: 3; variance explained: [0.1879673  0.12157818 0.06081048]\n",
      "0.37035596\n",
      "\n",
      "\n",
      "layer= 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4391.06it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4918.79it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5824.11it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5845.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:23; n_components: 1; variance explained: [0.18853156]\n",
      "0.18853156\n",
      "model:bigscience-T0; module:encoder; layer:23; n_components: 2; variance explained: [0.18853177 0.10610338]\n",
      "0.29463515\n",
      "model:bigscience-T0; module:encoder; layer:23; n_components: 3; variance explained: [0.1885317  0.10610352 0.06170622]\n",
      "0.35634142\n",
      "\n",
      "\n",
      "layer= 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4752.68it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5486.22it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5585.68it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5434.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:encoder; layer:24; n_components: 1; variance explained: [0.12169816]\n",
      "0.12169816\n",
      "model:bigscience-T0; module:encoder; layer:24; n_components: 2; variance explained: [0.12169814 0.05561725]\n",
      "0.17731538\n",
      "model:bigscience-T0; module:encoder; layer:24; n_components: 3; variance explained: [0.12169813 0.05561724 0.04918166]\n",
      "0.22649701\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for layer in range(0, 10):\n",
    "for layer in range(0, 25):\n",
    "# for layer in range(24, 25):\n",
    "    print('layer=', layer)\n",
    "    file_names, prompt_names = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if row['name'] in use_pattern:\n",
    "            file_names.append(f\"{task}/{model}/{module}/{row['name']}/hidden_represenations_layer{layer}_avg.hdf5\",)\n",
    "            prompt_names.append(row['name'])\n",
    "\n",
    "\n",
    "    # load hidden representations from hdf5 file\n",
    "    representations = None\n",
    "    classes = []\n",
    "    n_sequences = 0\n",
    "\n",
    "    for idx, file_name in enumerate(file_names):\n",
    "        hidden_representations = load_hidden_representations_from_hdf5(os.path.join(log_dir, file_name))\n",
    "        # print(hidden_representations.shape)\n",
    "        n_sequences = hidden_representations.shape[0]\n",
    "\n",
    "        if representations is None:\n",
    "            representations = hidden_representations\n",
    "        else:\n",
    "            representations = np.concatenate((representations, hidden_representations), axis=0)\n",
    "\n",
    "        classes += n_sequences * [idx] # assign representations to classes\n",
    "    \n",
    "    classes = np.asarray(classes)\n",
    "\n",
    "    # shuffle representations and classes\n",
    "    X, y = unison_shuffled_copies(representations, classes)\n",
    "    print(X.shape, y.shape)\n",
    "\n",
    "    # perform PCA on hidden representations\n",
    "    print('PCA for prompts:', prompt_names)\n",
    "\n",
    "    for n_components in range(1, 4):\n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca.fit(X)\n",
    "\n",
    "        # variance explained by each of the principal components\n",
    "        print(f\"model:{model}; module:{module}; layer:{layer}; n_components: {n_components}; variance explained: {pca.explained_variance_ratio_}\")\n",
    "        print(np.sum(pca.explained_variance_ratio_))\n",
    "    print('\\n')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
