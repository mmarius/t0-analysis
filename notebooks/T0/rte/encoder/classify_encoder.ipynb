{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from utils import load_hidden_representations_from_hdf5, read_templates_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "log_dir = \"/logfiles\"\n",
    "model = \"bigscience-T0\"\n",
    "module = \"encoder\"\n",
    "task = \"rte\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions\n",
    "assert model == \"bigscience-T0\"\n",
    "assert module == \"encoder\"\n",
    "assert task == \"rte\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>template</th>\n",
       "      <th>category</th>\n",
       "      <th>includes_targets</th>\n",
       "      <th>targets</th>\n",
       "      <th>target_ids</th>\n",
       "      <th>shuffle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_3_yes_no_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} Yes or No?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mnli_crowdsource_with_targets</td>\n",
       "      <td>{premise} Using only the above description and...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>based_on_previous_passage_with_targets</td>\n",
       "      <td>{premise} Based on the previous passage, is it...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>infer_with_targets</td>\n",
       "      <td>Suppose {premise} Can we infer that \"{hypothes...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>follow_with_targets</td>\n",
       "      <td>Given that {premise} Does it follow that {hypo...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>imply_with_targets</td>\n",
       "      <td>{premise} Question: Does this imply that \"{hyp...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>guaranteed_with_targets</td>\n",
       "      <td>Given {premise} Is it guaranteed true that \"{h...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>justified_with_targets</td>\n",
       "      <td>{premise} Are we justified in saying that \"{hy...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>must_be_true_with_targets</td>\n",
       "      <td>Given that {premise} Therefore, it must be tru...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>should_assume_with_targets</td>\n",
       "      <td>Given {premise} Should we assume that \"{hypoth...</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt_3_true_false_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} True or False?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁True, ▁Fal</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt_3_cat_dog_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} Cat or Dog?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Cat, ▁Dog</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt_3_yes_no_without_targets</td>\n",
       "      <td>{premise} Question: {hypothesis}?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name  \\\n",
       "0                gpt_3_yes_no_with_targets   \n",
       "1            mnli_crowdsource_with_targets   \n",
       "2   based_on_previous_passage_with_targets   \n",
       "3                       infer_with_targets   \n",
       "4                      follow_with_targets   \n",
       "5                       imply_with_targets   \n",
       "6                  guaranteed_with_targets   \n",
       "7                   justified_with_targets   \n",
       "8                must_be_true_with_targets   \n",
       "9               should_assume_with_targets   \n",
       "10           gpt_3_true_false_with_targets   \n",
       "11              gpt_3_cat_dog_with_targets   \n",
       "12            gpt_3_yes_no_without_targets   \n",
       "\n",
       "                                             template     category  \\\n",
       "0         {premise} Question: {hypothesis} Yes or No?  instructive   \n",
       "1   {premise} Using only the above description and...  instructive   \n",
       "2   {premise} Based on the previous passage, is it...  instructive   \n",
       "3   Suppose {premise} Can we infer that \"{hypothes...  instructive   \n",
       "4   Given that {premise} Does it follow that {hypo...  instructive   \n",
       "5   {premise} Question: Does this imply that \"{hyp...  instructive   \n",
       "6   Given {premise} Is it guaranteed true that \"{h...  instructive   \n",
       "7   {premise} Are we justified in saying that \"{hy...  instructive   \n",
       "8   Given that {premise} Therefore, it must be tru...  instructive   \n",
       "9   Given {premise} Should we assume that \"{hypoth...  instructive   \n",
       "10    {premise} Question: {hypothesis} True or False?  instructive   \n",
       "11       {premise} Question: {hypothesis} Cat or Dog?  instructive   \n",
       "12                  {premise} Question: {hypothesis}?  instructive   \n",
       "\n",
       "    includes_targets      targets target_ids  shuffle  \n",
       "0               True    ▁Yes, ▁No       0, 1    False  \n",
       "1               True    ▁Yes, ▁No       0, 1    False  \n",
       "2               True    ▁Yes, ▁No       0, 1    False  \n",
       "3               True    ▁Yes, ▁No       0, 1    False  \n",
       "4               True    ▁Yes, ▁No       0, 1    False  \n",
       "5               True    ▁Yes, ▁No       0, 1    False  \n",
       "6               True    ▁Yes, ▁No       0, 1    False  \n",
       "7               True    ▁Yes, ▁No       0, 1    False  \n",
       "8               True    ▁Yes, ▁No       0, 1    False  \n",
       "9               True    ▁Yes, ▁No       0, 1    False  \n",
       "10              True  ▁True, ▁Fal       0, 1    False  \n",
       "11              True   ▁Cat, ▁Dog       0, 1    False  \n",
       "12             False    ▁Yes, ▁No       0, 1    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/all.csv\")\n",
    "# df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/fixed_prompt.csv\")\n",
    "# df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/fixed_target_yes_no.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    # from: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pattern = [\n",
    "    \"gpt_3_yes_no_with_targets\",\n",
    "    # \"mnli_crowdsource_with_targets\",\n",
    "    # \"based_on_previous_passage_with_targets\",\n",
    "    # \"infer_with_targets\",\n",
    "    # \"follow_with_targets\",\n",
    "    # \"imply_with_targets\",\n",
    "    # \"guaranteed_with_targets\",\n",
    "    # \"justified_with_targets\",\n",
    "    # \"must_be_true_with_targets\",\n",
    "    # \"should_assume_with_targets\",\n",
    "    \"gpt_3_true_false_with_targets\",\n",
    "    # \"gpt_3_cat_dog_with_targets\",\n",
    "    # \"gpt_3_yes_no_without_targets\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5372.09it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5862.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=0; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4339.45it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5566.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=1; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4093.21it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5337.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=2; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3400.93it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 6106.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=3; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3546.17it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4923.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=4; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3688.30it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5085.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=5; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3539.51it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5584.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=6; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4414.59it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5091.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=7; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4356.06it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5423.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=8; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3492.73it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5221.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=9; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4198.93it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5353.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=10; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3851.17it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5199.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=11; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4397.43it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5312.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=12; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3696.03it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5804.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=13; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3228.17it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4203.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=14; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4473.23it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5115.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=15; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3981.91it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5592.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=16; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3124.77it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5874.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=17; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4213.01it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5673.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=18; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4365.80it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4905.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=19; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4124.69it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4408.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=20; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4243.99it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5389.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=21; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4233.24it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5563.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=22; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4074.95it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5559.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=23; accuracy on training data:  1.0\n",
      "\n",
      "\n",
      "layer: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3912.10it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5572.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 4096) (554,)\n",
      "classifying between: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=24; accuracy on training data:  0.9963898916967509\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for layer in range(0, 10):\n",
    "for layer in range(0, 25):\n",
    "# for layer in range(24, 25):\n",
    "    \n",
    "    print(\"layer:\", layer)\n",
    "    file_names, prompt_names = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if row['name'] in use_pattern:\n",
    "            file_names.append(f\"{task}/{model}/{module}/{row['name']}/hidden_represenations_layer{layer}_avg.hdf5\",)\n",
    "            prompt_names.append(row['name'])\n",
    "\n",
    "    # load hidden representations from hdf5 file\n",
    "    representations = None\n",
    "    classes = []\n",
    "    n_sequences = 0\n",
    "\n",
    "    for idx, file_name in enumerate(file_names):\n",
    "        hidden_representations = load_hidden_representations_from_hdf5(os.path.join(log_dir, file_name))\n",
    "        # print(hidden_representations.shape)\n",
    "        n_sequences = hidden_representations.shape[0]\n",
    "\n",
    "        if representations is None:\n",
    "            representations = hidden_representations\n",
    "        else:\n",
    "            representations = np.concatenate((representations, hidden_representations), axis=0)\n",
    "\n",
    "        classes += n_sequences * [idx] # assign representations to classes\n",
    "    \n",
    "    classes = np.asarray(classes)\n",
    "\n",
    "    # shuffle representations and classes\n",
    "    X, y = unison_shuffled_copies(representations, classes)\n",
    "    print(X.shape, y.shape)\n",
    "\n",
    "    # train linear classifier\n",
    "    # multi_class='multinomial' uses a CE loss\n",
    "    print('classifying between:', prompt_names)\n",
    "    clf = LogisticRegression(random_state=0, max_iter=2000, multi_class='multinomial').fit(X, y)\n",
    "    \n",
    "    print(f'layer={layer}; accuracy on training data: ', clf.score(X, y))\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
