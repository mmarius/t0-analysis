{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from utils import load_hidden_representations_from_hdf5, read_templates_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "log_dir = \"/logfiles\"\n",
    "model = \"bigscience-T0\" # bigscience-T0_B or bigscience-T0\n",
    "module = \"decoder\"\n",
    "task = \"rte\"\n",
    "# task = \"cb\"\n",
    "# task = \"wic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>template</th>\n",
       "      <th>category</th>\n",
       "      <th>includes_targets</th>\n",
       "      <th>targets</th>\n",
       "      <th>target_ids</th>\n",
       "      <th>shuffle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt_3_yes_no_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} Yes or No?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt_3_true_false_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} True or False?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁True, ▁Fal</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt_3_cat_dog_with_targets</td>\n",
       "      <td>{premise} Question: {hypothesis} Cat or Dog?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>True</td>\n",
       "      <td>▁Cat, ▁Dog</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt_3_yes_no_without_targets</td>\n",
       "      <td>{premise} Question: {hypothesis}?</td>\n",
       "      <td>instructive</td>\n",
       "      <td>False</td>\n",
       "      <td>▁Yes, ▁No</td>\n",
       "      <td>0, 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  \\\n",
       "0      gpt_3_yes_no_with_targets   \n",
       "1  gpt_3_true_false_with_targets   \n",
       "2     gpt_3_cat_dog_with_targets   \n",
       "3   gpt_3_yes_no_without_targets   \n",
       "\n",
       "                                          template     category  \\\n",
       "0      {premise} Question: {hypothesis} Yes or No?  instructive   \n",
       "1  {premise} Question: {hypothesis} True or False?  instructive   \n",
       "2     {premise} Question: {hypothesis} Cat or Dog?  instructive   \n",
       "3                {premise} Question: {hypothesis}?  instructive   \n",
       "\n",
       "   includes_targets      targets target_ids  shuffle  \n",
       "0              True    ▁Yes, ▁No       0, 1    False  \n",
       "1              True  ▁True, ▁Fal       0, 1    False  \n",
       "2              True   ▁Cat, ▁Dog       0, 1    False  \n",
       "3             False    ▁Yes, ▁No       0, 1    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/fixed_prompt.csv\")\n",
    "# df = read_templates_from_file(f\"/t0-analysis/prompts/{task}/fixed_target_yes_no.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    # from: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == 'rte':\n",
    "    use_pattern = [\n",
    "        \"gpt_3_yes_no_with_targets\",\n",
    "        \"gpt_3_true_false_with_targets\",\n",
    "        \"gpt_3_cat_dog_with_targets\",\n",
    "        \"gpt_3_yes_no_without_targets\",\n",
    "    ]\n",
    "elif task == 'cb':\n",
    "    use_pattern = [\n",
    "        \"null_pattern\",\n",
    "        \"null_pattern_reversed\",\n",
    "        \"gpt_3_true_false_neither\",\n",
    "        \"gpt_3_yes_no_maybe\",\n",
    "        \"mnli_crowdsource\",\n",
    "        \"always_sometimes_never\",\n",
    "        \"based_on_previous_passage\",\n",
    "        \"infer\",\n",
    "        \"claim\",\n",
    "        \"consider\",\n",
    "        \"follow\",\n",
    "        \"imply\",\n",
    "        \"guaranteed\",\n",
    "        \"guaranteed_possible\",\n",
    "        \"justified\",\n",
    "        \"must_be_true\",\n",
    "        \"should_assume\",\n",
    "        \"take_the_following\",\n",
    "    ]\n",
    "elif task == 'wic':\n",
    "    use_pattern = [\n",
    "        \"gpt_3\",\n",
    "        \"gpt_3_yes_no\",\n",
    "        \"affirmation\",\n",
    "        \"grammar_homework\",\n",
    "        \"polysemous\",\n",
    "        \"question_context\",\n",
    "        \"question_meaning\",\n",
    "        \"question_meaning_yes_no\",\n",
    "        \"same_sense\",\n",
    "        \"similar_sense\",\n",
    "        \"similar_sense_yes_no\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: 0\tlayer: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5045.59it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4181.94it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5111.38it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5506.81it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:555: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ / total_var.sum()\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:555: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ / total_var.sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:0; n_components: 1; variance explained: [nan]\n",
      "nan\n",
      "model:bigscience-T0; module:decoder; token:0; layer:0; n_components: 2; variance explained: [nan nan]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:555: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ / total_var.sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:bigscience-T0; module:decoder; token:0; layer:0; n_components: 3; variance explained: [nan nan nan]\n",
      "nan\n",
      "\n",
      "\n",
      "token: 0\tlayer: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4144.63it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5331.98it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4954.40it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5512.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:1; n_components: 1; variance explained: [0.91972893]\n",
      "0.91972893\n",
      "model:bigscience-T0; module:decoder; token:0; layer:1; n_components: 2; variance explained: [0.91972893 0.01331339]\n",
      "0.93304235\n",
      "model:bigscience-T0; module:decoder; token:0; layer:1; n_components: 3; variance explained: [0.91972893 0.01331339 0.00667707]\n",
      "0.93971944\n",
      "\n",
      "\n",
      "token: 0\tlayer: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4224.27it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5555.10it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5527.12it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5545.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:2; n_components: 1; variance explained: [0.9320126]\n",
      "0.9320126\n",
      "model:bigscience-T0; module:decoder; token:0; layer:2; n_components: 2; variance explained: [0.9320125  0.03345007]\n",
      "0.96546257\n",
      "model:bigscience-T0; module:decoder; token:0; layer:2; n_components: 3; variance explained: [0.9320125  0.03345009 0.00689409]\n",
      "0.9723567\n",
      "\n",
      "\n",
      "token: 0\tlayer: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4046.20it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4823.88it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5532.64it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4913.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:3; n_components: 1; variance explained: [0.9607144]\n",
      "0.9607144\n",
      "model:bigscience-T0; module:decoder; token:0; layer:3; n_components: 2; variance explained: [0.9607144  0.01350653]\n",
      "0.97422093\n",
      "model:bigscience-T0; module:decoder; token:0; layer:3; n_components: 3; variance explained: [0.9607144  0.01350654 0.00312071]\n",
      "0.97734165\n",
      "\n",
      "\n",
      "token: 0\tlayer: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3944.48it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5447.53it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3352.03it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5421.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:4; n_components: 1; variance explained: [0.96854216]\n",
      "0.96854216\n",
      "model:bigscience-T0; module:decoder; token:0; layer:4; n_components: 2; variance explained: [0.96854216 0.01049002]\n",
      "0.97903216\n",
      "model:bigscience-T0; module:decoder; token:0; layer:4; n_components: 3; variance explained: [0.96854186 0.01049002 0.00187797]\n",
      "0.9809098\n",
      "\n",
      "\n",
      "token: 0\tlayer: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3375.35it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5436.90it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5217.38it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5341.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:5; n_components: 1; variance explained: [0.96704036]\n",
      "0.96704036\n",
      "model:bigscience-T0; module:decoder; token:0; layer:5; n_components: 2; variance explained: [0.9670402  0.01021816]\n",
      "0.9772583\n",
      "model:bigscience-T0; module:decoder; token:0; layer:5; n_components: 3; variance explained: [0.9670402  0.01021816 0.00195991]\n",
      "0.97921824\n",
      "\n",
      "\n",
      "token: 0\tlayer: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3507.31it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5389.31it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5570.23it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5455.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:6; n_components: 1; variance explained: [0.9745324]\n",
      "0.9745324\n",
      "model:bigscience-T0; module:decoder; token:0; layer:6; n_components: 2; variance explained: [0.97453237 0.00750657]\n",
      "0.9820389\n",
      "model:bigscience-T0; module:decoder; token:0; layer:6; n_components: 3; variance explained: [0.9745324  0.00750658 0.00218515]\n",
      "0.98422414\n",
      "\n",
      "\n",
      "token: 0\tlayer: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3562.64it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5716.03it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5039.33it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5421.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:7; n_components: 1; variance explained: [0.9913897]\n",
      "0.9913897\n",
      "model:bigscience-T0; module:decoder; token:0; layer:7; n_components: 2; variance explained: [0.9913896 0.002824 ]\n",
      "0.9942136\n",
      "model:bigscience-T0; module:decoder; token:0; layer:7; n_components: 3; variance explained: [0.9913896  0.002824   0.00160309]\n",
      "0.99581665\n",
      "\n",
      "\n",
      "token: 0\tlayer: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3658.23it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5477.30it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5488.22it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5597.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:8; n_components: 1; variance explained: [0.9919332]\n",
      "0.9919332\n",
      "model:bigscience-T0; module:decoder; token:0; layer:8; n_components: 2; variance explained: [0.99193347 0.00197831]\n",
      "0.9939118\n",
      "model:bigscience-T0; module:decoder; token:0; layer:8; n_components: 3; variance explained: [0.9919332  0.00197831 0.0014532 ]\n",
      "0.9953648\n",
      "\n",
      "\n",
      "token: 0\tlayer: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3581.29it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5517.33it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5265.02it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4055.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:9; n_components: 1; variance explained: [0.99209225]\n",
      "0.99209225\n",
      "model:bigscience-T0; module:decoder; token:0; layer:9; n_components: 2; variance explained: [0.99209225 0.00178917]\n",
      "0.9938814\n",
      "model:bigscience-T0; module:decoder; token:0; layer:9; n_components: 3; variance explained: [0.99209225 0.00178917 0.00148302]\n",
      "0.9953644\n",
      "\n",
      "\n",
      "token: 0\tlayer: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3366.20it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5275.66it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5453.44it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5482.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:10; n_components: 1; variance explained: [0.99220496]\n",
      "0.99220496\n",
      "model:bigscience-T0; module:decoder; token:0; layer:10; n_components: 2; variance explained: [0.99220496 0.00165896]\n",
      "0.99386394\n",
      "model:bigscience-T0; module:decoder; token:0; layer:10; n_components: 3; variance explained: [0.99220496 0.00165896 0.00149969]\n",
      "0.99536365\n",
      "\n",
      "\n",
      "token: 0\tlayer: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4184.42it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5232.82it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5235.44it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5562.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:11; n_components: 1; variance explained: [0.9924607]\n",
      "0.9924607\n",
      "model:bigscience-T0; module:decoder; token:0; layer:11; n_components: 2; variance explained: [0.99246055 0.00163718]\n",
      "0.9940977\n",
      "model:bigscience-T0; module:decoder; token:0; layer:11; n_components: 3; variance explained: [0.9924607  0.00163718 0.00146603]\n",
      "0.9955639\n",
      "\n",
      "\n",
      "token: 0\tlayer: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3745.01it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5171.22it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5192.80it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5479.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:12; n_components: 1; variance explained: [0.9925776]\n",
      "0.9925776\n",
      "model:bigscience-T0; module:decoder; token:0; layer:12; n_components: 2; variance explained: [0.9925776  0.00165891]\n",
      "0.9942365\n",
      "model:bigscience-T0; module:decoder; token:0; layer:12; n_components: 3; variance explained: [0.9925776  0.00165891 0.00141059]\n",
      "0.99564713\n",
      "\n",
      "\n",
      "token: 0\tlayer: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4212.00it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5467.63it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5061.17it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5584.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:13; n_components: 1; variance explained: [0.9894708]\n",
      "0.9894708\n",
      "model:bigscience-T0; module:decoder; token:0; layer:13; n_components: 2; variance explained: [0.9894708  0.00171337]\n",
      "0.9911842\n",
      "model:bigscience-T0; module:decoder; token:0; layer:13; n_components: 3; variance explained: [0.989471   0.00171337 0.00151224]\n",
      "0.99269664\n",
      "\n",
      "\n",
      "token: 0\tlayer: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4054.66it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5519.74it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5488.73it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5437.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:14; n_components: 1; variance explained: [0.9892674]\n",
      "0.9892674\n",
      "model:bigscience-T0; module:decoder; token:0; layer:14; n_components: 2; variance explained: [0.9892674  0.00174743]\n",
      "0.99101484\n",
      "model:bigscience-T0; module:decoder; token:0; layer:14; n_components: 3; variance explained: [0.9892674  0.00174743 0.00153754]\n",
      "0.9925524\n",
      "\n",
      "\n",
      "token: 0\tlayer: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3697.27it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5631.00it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4032.87it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5398.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:15; n_components: 1; variance explained: [0.988247]\n",
      "0.988247\n",
      "model:bigscience-T0; module:decoder; token:0; layer:15; n_components: 2; variance explained: [0.988247   0.00185204]\n",
      "0.990099\n",
      "model:bigscience-T0; module:decoder; token:0; layer:15; n_components: 3; variance explained: [0.988247   0.00185204 0.00150914]\n",
      "0.99160814\n",
      "\n",
      "\n",
      "token: 0\tlayer: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3399.70it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5783.38it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4917.91it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5163.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:16; n_components: 1; variance explained: [0.97942847]\n",
      "0.97942847\n",
      "model:bigscience-T0; module:decoder; token:0; layer:16; n_components: 2; variance explained: [0.9794287  0.00585025]\n",
      "0.98527896\n",
      "model:bigscience-T0; module:decoder; token:0; layer:16; n_components: 3; variance explained: [0.97942847 0.00585025 0.00228076]\n",
      "0.9875595\n",
      "\n",
      "\n",
      "token: 0\tlayer: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3676.56it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4798.00it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5468.81it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5326.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:17; n_components: 1; variance explained: [0.9784722]\n",
      "0.9784722\n",
      "model:bigscience-T0; module:decoder; token:0; layer:17; n_components: 2; variance explained: [0.97847193 0.00519226]\n",
      "0.9836642\n",
      "model:bigscience-T0; module:decoder; token:0; layer:17; n_components: 3; variance explained: [0.9784722  0.00519226 0.00238504]\n",
      "0.9860495\n",
      "\n",
      "\n",
      "token: 0\tlayer: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3768.76it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5455.10it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5178.71it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5417.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:18; n_components: 1; variance explained: [0.91452456]\n",
      "0.91452456\n",
      "model:bigscience-T0; module:decoder; token:0; layer:18; n_components: 2; variance explained: [0.9145247  0.01442506]\n",
      "0.9289497\n",
      "model:bigscience-T0; module:decoder; token:0; layer:18; n_components: 3; variance explained: [0.9145247  0.01442506 0.00687208]\n",
      "0.9358218\n",
      "\n",
      "\n",
      "token: 0\tlayer: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3377.97it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5116.09it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5485.96it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5511.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:19; n_components: 1; variance explained: [0.7389529]\n",
      "0.7389529\n",
      "model:bigscience-T0; module:decoder; token:0; layer:19; n_components: 2; variance explained: [0.738953   0.03401883]\n",
      "0.7729718\n",
      "model:bigscience-T0; module:decoder; token:0; layer:19; n_components: 3; variance explained: [0.738953   0.03401882 0.01450585]\n",
      "0.7874777\n",
      "\n",
      "\n",
      "token: 0\tlayer: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 2869.91it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4933.87it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4869.37it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5353.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:20; n_components: 1; variance explained: [0.5659779]\n",
      "0.5659779\n",
      "model:bigscience-T0; module:decoder; token:0; layer:20; n_components: 2; variance explained: [0.5659777 0.0846751]\n",
      "0.65065277\n",
      "model:bigscience-T0; module:decoder; token:0; layer:20; n_components: 3; variance explained: [0.5659779  0.0846751  0.04102185]\n",
      "0.6916748\n",
      "\n",
      "\n",
      "token: 0\tlayer: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3341.82it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4287.34it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4887.68it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4901.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:21; n_components: 1; variance explained: [0.5605061]\n",
      "0.5605061\n",
      "model:bigscience-T0; module:decoder; token:0; layer:21; n_components: 2; variance explained: [0.5605061  0.08886828]\n",
      "0.64937437\n",
      "model:bigscience-T0; module:decoder; token:0; layer:21; n_components: 3; variance explained: [0.56050617 0.08886831 0.03730233]\n",
      "0.6866768\n",
      "\n",
      "\n",
      "token: 0\tlayer: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3339.91it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5235.79it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4794.84it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5436.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:22; n_components: 1; variance explained: [0.6300503]\n",
      "0.6300503\n",
      "model:bigscience-T0; module:decoder; token:0; layer:22; n_components: 2; variance explained: [0.6300506  0.06979188]\n",
      "0.69984245\n",
      "model:bigscience-T0; module:decoder; token:0; layer:22; n_components: 3; variance explained: [0.6300503  0.06979188 0.04271581]\n",
      "0.742558\n",
      "\n",
      "\n",
      "token: 0\tlayer: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3767.37it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5504.52it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5342.72it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5267.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:23; n_components: 1; variance explained: [0.62818605]\n",
      "0.62818605\n",
      "model:bigscience-T0; module:decoder; token:0; layer:23; n_components: 2; variance explained: [0.62818605 0.07512952]\n",
      "0.70331556\n",
      "model:bigscience-T0; module:decoder; token:0; layer:23; n_components: 3; variance explained: [0.62818605 0.07512959 0.0367535 ]\n",
      "0.7400691\n",
      "\n",
      "\n",
      "token: 0\tlayer: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3639.24it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5591.73it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5555.16it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5480.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:0; layer:24; n_components: 1; variance explained: [0.87068355]\n",
      "0.87068355\n",
      "model:bigscience-T0; module:decoder; token:0; layer:24; n_components: 2; variance explained: [0.87068355 0.02679551]\n",
      "0.89747906\n",
      "model:bigscience-T0; module:decoder; token:0; layer:24; n_components: 3; variance explained: [0.87068355 0.02679548 0.01043749]\n",
      "0.90791655\n",
      "\n",
      "\n",
      "token: 1\tlayer: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3900.17it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5509.11it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4898.55it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4958.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:0; n_components: 1; variance explained: [0.32597634]\n",
      "0.32597634\n",
      "model:bigscience-T0; module:decoder; token:1; layer:0; n_components: 2; variance explained: [0.3259764 0.2266581]\n",
      "0.5526345\n",
      "model:bigscience-T0; module:decoder; token:1; layer:0; n_components: 3; variance explained: [0.3259764  0.22665812 0.13435166]\n",
      "0.6869862\n",
      "\n",
      "\n",
      "token: 1\tlayer: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 2897.41it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5651.08it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5071.71it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5661.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:1; n_components: 1; variance explained: [0.33147904]\n",
      "0.33147904\n",
      "model:bigscience-T0; module:decoder; token:1; layer:1; n_components: 2; variance explained: [0.33147913 0.22899392]\n",
      "0.5604731\n",
      "model:bigscience-T0; module:decoder; token:1; layer:1; n_components: 3; variance explained: [0.33147913 0.22899364 0.13159114]\n",
      "0.6920639\n",
      "\n",
      "\n",
      "token: 1\tlayer: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4371.19it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5556.80it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5323.26it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5335.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:2; n_components: 1; variance explained: [0.32681495]\n",
      "0.32681495\n",
      "model:bigscience-T0; module:decoder; token:1; layer:2; n_components: 2; variance explained: [0.3268151  0.24740723]\n",
      "0.5742223\n",
      "model:bigscience-T0; module:decoder; token:1; layer:2; n_components: 3; variance explained: [0.32681513 0.24740735 0.12817276]\n",
      "0.7023952\n",
      "\n",
      "\n",
      "token: 1\tlayer: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4091.05it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5543.02it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5182.91it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5517.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:3; n_components: 1; variance explained: [0.49900874]\n",
      "0.49900874\n",
      "model:bigscience-T0; module:decoder; token:1; layer:3; n_components: 2; variance explained: [0.49900883 0.18779676]\n",
      "0.6868056\n",
      "model:bigscience-T0; module:decoder; token:1; layer:3; n_components: 3; variance explained: [0.49900907 0.1877967  0.09631664]\n",
      "0.7831224\n",
      "\n",
      "\n",
      "token: 1\tlayer: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3483.14it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5473.74it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5517.43it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5608.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:4; n_components: 1; variance explained: [0.71420056]\n",
      "0.71420056\n",
      "model:bigscience-T0; module:decoder; token:1; layer:4; n_components: 2; variance explained: [0.71420056 0.10283156]\n",
      "0.8170321\n",
      "model:bigscience-T0; module:decoder; token:1; layer:4; n_components: 3; variance explained: [0.7142008  0.10283158 0.05529137]\n",
      "0.87232375\n",
      "\n",
      "\n",
      "token: 1\tlayer: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4235.85it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 1826.61it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4868.02it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4845.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:5; n_components: 1; variance explained: [0.79267067]\n",
      "0.79267067\n",
      "model:bigscience-T0; module:decoder; token:1; layer:5; n_components: 2; variance explained: [0.79267067 0.07159963]\n",
      "0.86427027\n",
      "model:bigscience-T0; module:decoder; token:1; layer:5; n_components: 3; variance explained: [0.79267067 0.0715997  0.03950733]\n",
      "0.9037777\n",
      "\n",
      "\n",
      "token: 1\tlayer: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3645.53it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5497.56it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5036.31it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5481.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:6; n_components: 1; variance explained: [0.8458302]\n",
      "0.8458302\n",
      "model:bigscience-T0; module:decoder; token:1; layer:6; n_components: 2; variance explained: [0.8458302  0.05332671]\n",
      "0.8991569\n",
      "model:bigscience-T0; module:decoder; token:1; layer:6; n_components: 3; variance explained: [0.8458302  0.05332672 0.02810195]\n",
      "0.92725885\n",
      "\n",
      "\n",
      "token: 1\tlayer: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4138.87it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5565.30it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5363.66it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5430.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:7; n_components: 1; variance explained: [0.906834]\n",
      "0.906834\n",
      "model:bigscience-T0; module:decoder; token:1; layer:7; n_components: 2; variance explained: [0.906834   0.03123203]\n",
      "0.93806607\n",
      "model:bigscience-T0; module:decoder; token:1; layer:7; n_components: 3; variance explained: [0.906834   0.031232   0.01654864]\n",
      "0.95461464\n",
      "\n",
      "\n",
      "token: 1\tlayer: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3332.77it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5601.28it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4774.81it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5488.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:8; n_components: 1; variance explained: [0.9203834]\n",
      "0.9203834\n",
      "model:bigscience-T0; module:decoder; token:1; layer:8; n_components: 2; variance explained: [0.9203834  0.02662104]\n",
      "0.94700444\n",
      "model:bigscience-T0; module:decoder; token:1; layer:8; n_components: 3; variance explained: [0.9203834  0.02662104 0.01394355]\n",
      "0.960948\n",
      "\n",
      "\n",
      "token: 1\tlayer: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4256.38it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5436.19it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5650.45it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5141.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:9; n_components: 1; variance explained: [0.9298281]\n",
      "0.9298281\n",
      "model:bigscience-T0; module:decoder; token:1; layer:9; n_components: 2; variance explained: [0.929828   0.02506897]\n",
      "0.9548969\n",
      "model:bigscience-T0; module:decoder; token:1; layer:9; n_components: 3; variance explained: [0.929828   0.02506899 0.01161601]\n",
      "0.966513\n",
      "\n",
      "\n",
      "token: 1\tlayer: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3806.72it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5769.30it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5259.49it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5481.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:10; n_components: 1; variance explained: [0.9346072]\n",
      "0.9346072\n",
      "model:bigscience-T0; module:decoder; token:1; layer:10; n_components: 2; variance explained: [0.9346073  0.02313813]\n",
      "0.95774543\n",
      "model:bigscience-T0; module:decoder; token:1; layer:10; n_components: 3; variance explained: [0.934607   0.02313814 0.01028337]\n",
      "0.96802855\n",
      "\n",
      "\n",
      "token: 1\tlayer: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3396.95it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5541.46it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4732.76it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5093.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:11; n_components: 1; variance explained: [0.932689]\n",
      "0.932689\n",
      "model:bigscience-T0; module:decoder; token:1; layer:11; n_components: 2; variance explained: [0.932689   0.02449386]\n",
      "0.9571829\n",
      "model:bigscience-T0; module:decoder; token:1; layer:11; n_components: 3; variance explained: [0.932689   0.02449389 0.0091443 ]\n",
      "0.9663272\n",
      "\n",
      "\n",
      "token: 1\tlayer: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3544.30it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5462.64it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5324.70it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4802.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:12; n_components: 1; variance explained: [0.92174554]\n",
      "0.92174554\n",
      "model:bigscience-T0; module:decoder; token:1; layer:12; n_components: 2; variance explained: [0.92174554 0.02848436]\n",
      "0.9502299\n",
      "model:bigscience-T0; module:decoder; token:1; layer:12; n_components: 3; variance explained: [0.92174536 0.02848436 0.01033071]\n",
      "0.96056044\n",
      "\n",
      "\n",
      "token: 1\tlayer: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3033.64it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5525.99it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5141.83it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5421.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:13; n_components: 1; variance explained: [0.8982214]\n",
      "0.8982214\n",
      "model:bigscience-T0; module:decoder; token:1; layer:13; n_components: 2; variance explained: [0.8982215  0.03625587]\n",
      "0.9344774\n",
      "model:bigscience-T0; module:decoder; token:1; layer:13; n_components: 3; variance explained: [0.8982214  0.03625586 0.0137269 ]\n",
      "0.9482041\n",
      "\n",
      "\n",
      "token: 1\tlayer: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3954.92it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5578.39it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5700.46it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5572.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:14; n_components: 1; variance explained: [0.88551915]\n",
      "0.88551915\n",
      "model:bigscience-T0; module:decoder; token:1; layer:14; n_components: 2; variance explained: [0.88551915 0.03835036]\n",
      "0.9238695\n",
      "model:bigscience-T0; module:decoder; token:1; layer:14; n_components: 3; variance explained: [0.885519   0.03835038 0.01587257]\n",
      "0.93974197\n",
      "\n",
      "\n",
      "token: 1\tlayer: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3551.50it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5562.36it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4558.13it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5541.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:15; n_components: 1; variance explained: [0.8507134]\n",
      "0.8507134\n",
      "model:bigscience-T0; module:decoder; token:1; layer:15; n_components: 2; variance explained: [0.85071325 0.04802972]\n",
      "0.898743\n",
      "model:bigscience-T0; module:decoder; token:1; layer:15; n_components: 3; variance explained: [0.85071325 0.04802975 0.02116202]\n",
      "0.919905\n",
      "\n",
      "\n",
      "token: 1\tlayer: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3500.80it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5116.69it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4773.74it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5207.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:16; n_components: 1; variance explained: [0.77713555]\n",
      "0.77713555\n",
      "model:bigscience-T0; module:decoder; token:1; layer:16; n_components: 2; variance explained: [0.77713555 0.06656523]\n",
      "0.84370077\n",
      "model:bigscience-T0; module:decoder; token:1; layer:16; n_components: 3; variance explained: [0.77713567 0.06656526 0.03343173]\n",
      "0.87713265\n",
      "\n",
      "\n",
      "token: 1\tlayer: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4130.70it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5507.49it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4569.16it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5434.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:17; n_components: 1; variance explained: [0.66346735]\n",
      "0.66346735\n",
      "model:bigscience-T0; module:decoder; token:1; layer:17; n_components: 2; variance explained: [0.66346735 0.09476217]\n",
      "0.7582295\n",
      "model:bigscience-T0; module:decoder; token:1; layer:17; n_components: 3; variance explained: [0.66346735 0.09476215 0.05176894]\n",
      "0.80999845\n",
      "\n",
      "\n",
      "token: 1\tlayer: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3455.93it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5435.68it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5047.34it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5362.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:18; n_components: 1; variance explained: [0.56817317]\n",
      "0.56817317\n",
      "model:bigscience-T0; module:decoder; token:1; layer:18; n_components: 2; variance explained: [0.5681731  0.11993741]\n",
      "0.68811053\n",
      "model:bigscience-T0; module:decoder; token:1; layer:18; n_components: 3; variance explained: [0.56817317 0.11993745 0.06452591]\n",
      "0.7526365\n",
      "\n",
      "\n",
      "token: 1\tlayer: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3473.22it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5494.55it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5710.52it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4736.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:19; n_components: 1; variance explained: [0.47461566]\n",
      "0.47461566\n",
      "model:bigscience-T0; module:decoder; token:1; layer:19; n_components: 2; variance explained: [0.47461584 0.13625516]\n",
      "0.610871\n",
      "model:bigscience-T0; module:decoder; token:1; layer:19; n_components: 3; variance explained: [0.47461578 0.1362552  0.07650257]\n",
      "0.6873735\n",
      "\n",
      "\n",
      "token: 1\tlayer: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3349.05it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5518.53it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4795.71it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5450.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:20; n_components: 1; variance explained: [0.48221672]\n",
      "0.48221672\n",
      "model:bigscience-T0; module:decoder; token:1; layer:20; n_components: 2; variance explained: [0.4822168  0.12931912]\n",
      "0.6115359\n",
      "model:bigscience-T0; module:decoder; token:1; layer:20; n_components: 3; variance explained: [0.4822168  0.12931907 0.08474886]\n",
      "0.6962848\n",
      "\n",
      "\n",
      "token: 1\tlayer: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3546.46it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5011.07it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5510.13it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5636.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:21; n_components: 1; variance explained: [0.45150796]\n",
      "0.45150796\n",
      "model:bigscience-T0; module:decoder; token:1; layer:21; n_components: 2; variance explained: [0.45150802 0.12431841]\n",
      "0.5758264\n",
      "model:bigscience-T0; module:decoder; token:1; layer:21; n_components: 3; variance explained: [0.45150813 0.12431841 0.0957318 ]\n",
      "0.6715583\n",
      "\n",
      "\n",
      "token: 1\tlayer: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4320.34it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4377.64it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5282.40it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5371.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:22; n_components: 1; variance explained: [0.26628307]\n",
      "0.26628307\n",
      "model:bigscience-T0; module:decoder; token:1; layer:22; n_components: 2; variance explained: [0.266283  0.1741751]\n",
      "0.44045812\n",
      "model:bigscience-T0; module:decoder; token:1; layer:22; n_components: 3; variance explained: [0.26628307 0.17417528 0.11407206]\n",
      "0.55453044\n",
      "\n",
      "\n",
      "token: 1\tlayer: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3359.20it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3992.06it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5588.45it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5444.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:23; n_components: 1; variance explained: [0.38359633]\n",
      "0.38359633\n",
      "model:bigscience-T0; module:decoder; token:1; layer:23; n_components: 2; variance explained: [0.38359624 0.1520612 ]\n",
      "0.5356574\n",
      "model:bigscience-T0; module:decoder; token:1; layer:23; n_components: 3; variance explained: [0.38359615 0.15206118 0.08985174]\n",
      "0.6255091\n",
      "\n",
      "\n",
      "token: 1\tlayer: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 3806.86it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 5631.85it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4996.57it/s]\n",
      "Reading embeddings: 100%|██████████| 277/277 [00:00<00:00, 4125.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1108, 4096) (1108,)\n",
      "PCA for prompts: ['gpt_3_yes_no_with_targets', 'gpt_3_true_false_with_targets', 'gpt_3_cat_dog_with_targets', 'gpt_3_yes_no_without_targets']\n",
      "model:bigscience-T0; module:decoder; token:1; layer:24; n_components: 1; variance explained: [0.76760083]\n",
      "0.76760083\n",
      "model:bigscience-T0; module:decoder; token:1; layer:24; n_components: 2; variance explained: [0.7676007  0.10794663]\n",
      "0.87554735\n",
      "model:bigscience-T0; module:decoder; token:1; layer:24; n_components: 3; variance explained: [0.7676007  0.10794659 0.03061317]\n",
      "0.9061605\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(2):\n",
    "    # for layer in range(0, 10):\n",
    "    for layer in range(0, 25):\n",
    "    # for layer in range(24, 25):\n",
    "        print(f\"token: {t}\\tlayer: {layer}\")\n",
    "        file_names, prompt_names = [], []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            if row['name'] in use_pattern:\n",
    "                file_names.append(f\"{task}/{model}/{module}/{row['name']}/hidden_represenations_t{t}_layer{layer}_avg.hdf5\",)\n",
    "                prompt_names.append(row['name'])\n",
    "\n",
    "\n",
    "        # load hidden representations from hdf5 file\n",
    "        representations = None\n",
    "        classes = []\n",
    "        n_sequences = 0\n",
    "\n",
    "        for idx, file_name in enumerate(file_names):\n",
    "            hidden_representations = load_hidden_representations_from_hdf5(os.path.join(log_dir, file_name))\n",
    "            # print(hidden_representations.shape)\n",
    "            n_sequences = hidden_representations.shape[0]\n",
    "\n",
    "            if representations is None:\n",
    "                representations = hidden_representations\n",
    "            else:\n",
    "                representations = np.concatenate((representations, hidden_representations), axis=0)\n",
    "\n",
    "            classes += n_sequences * [idx] # assign representations to classes\n",
    "        \n",
    "        classes = np.asarray(classes)\n",
    "\n",
    "        # shuffle representations and classes\n",
    "        X, y = unison_shuffled_copies(representations, classes)\n",
    "        print(X.shape, y.shape)\n",
    "\n",
    "        # perform PCA on hidden representations\n",
    "        print('PCA for prompts:', prompt_names)\n",
    "\n",
    "        for n_components in range(1, 4):\n",
    "            pca = PCA(n_components=n_components)\n",
    "            pca.fit(X)\n",
    "\n",
    "            # variance explained by each of the principal components\n",
    "            print(f\"model:{model}; module:{module}; token:{t}; layer:{layer}; n_components: {n_components}; variance explained: {pca.explained_variance_ratio_}\")\n",
    "            print(np.sum(pca.explained_variance_ratio_))\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
